Priority,Epic,Feature,Task ID,Task Name,Task Type,Story Points,Sprint,Dependencies,Acceptance Criteria,Detailed AI Prompt
P1-Critical,Financial Integration,QuickBooks Online Integration,FIN-001,Create accounting integration database schema,Database Schema,3,1,None,"- New table: accounting_integrations (id, company_id, provider, access_token_encrypted, refresh_token_encrypted, realm_id, is_active, created_at, updated_at)
- New table: accounting_sync_logs (id, company_id, entity_type, entity_id, sync_status, error_message, synced_at)
- New table: chart_of_accounts_mapping (id, company_id, caskr_account_type, qbo_account_id, qbo_account_name)
- Indexes on company_id, sync_status, synced_at
- Foreign keys properly configured","Create a database migration for QuickBooks Online integration. The Caskr application uses PostgreSQL with Entity Framework Core 9.0.1. Create SQL migration files in the Database/initdb.d/ directory following the existing pattern (using IF NOT EXISTS for idempotent migrations). Include three new tables: 1) accounting_integrations to store OAuth tokens and provider configuration (supports multiple providers like QuickBooks, Xero, NetSuite), 2) accounting_sync_logs to track all sync operations with status and error messages for audit trail, 3) chart_of_accounts_mapping to map Caskr internal account types (COGS, WIP, Finished Goods, etc.) to external accounting system account IDs. Ensure all sensitive fields like access_token and refresh_token have '_encrypted' suffix to indicate encryption requirement. Add appropriate indexes for company_id lookups and sync_status filtering. Include updated_at timestamps for change tracking."
P1-Critical,Financial Integration,QuickBooks Online Integration,FIN-002,Create C# models for accounting integration,Backend Model,2,1,FIN-001,"- AccountingIntegration.cs entity with all fields
- AccountingSyncLog.cs entity
- ChartOfAccountsMapping.cs entity
- Enums: AccountingProvider, SyncStatus, CaskrAccountType
- Models added to CaskrDbContext with proper relationships","Create C# entity models for the accounting integration tables in Caskr.Server/Models/. Follow the existing model patterns in the codebase (see User.cs, Company.cs, Order.cs as examples). Create: 1) AccountingIntegration.cs with properties matching the database schema, using proper data annotations for validation ([Required], [MaxLength], etc.), 2) AccountingSyncLog.cs for tracking sync operations, 3) ChartOfAccountsMapping.cs for account mapping. Create enums: AccountingProvider (QuickBooks, Xero, NetSuite), SyncStatus (Pending, InProgress, Success, Failed), CaskrAccountType (COGS, WIP, FinishedGoods, RawMaterials, Barrels, etc.). Update CaskrDbContext.cs to include the new DbSet properties and configure relationships in OnModelCreating. Use snake_case column naming to match PostgreSQL convention (e.g., HasColumnName(""company_id"")). Ensure navigation properties are properly configured for Company relationships."
P1-Critical,Financial Integration,QuickBooks Online Integration,FIN-003,Install QuickBooks SDK NuGet package,Infrastructure,1,1,None,"- IppDotNetSdkForQuickBooksApiV3 package added to Caskr.server.csproj
- Package version documented
- dotnet restore successful","Add the official Intuit QuickBooks SDK to the Caskr.Server project. Update Caskr.Server/Caskr.server.csproj to include the NuGet package 'IppDotNetSdkForQuickBooksApiV3' (latest stable version). This SDK provides OAuth 2.0 authentication and API access to QuickBooks Online. After adding the package reference, run 'dotnet restore' to ensure the package installs correctly. Document the package version in a comment explaining it's for QuickBooks Online integration. Verify the package doesn't conflict with existing dependencies (especially Entity Framework Core 9.0.1, ASP.NET Core 8.0)."
P1-Critical,Financial Integration,QuickBooks Online Integration,FIN-004,Create QuickBooks OAuth service interface,Backend Service,2,1,None,"- IQuickBooksAuthService interface created
- Methods: GetAuthorizationUrl(), HandleCallback(), RefreshToken(), RevokeAccess()
- XML documentation comments on all methods
- Returns proper types (AuthorizationUrl, OAuthTokens, etc.)","Create an interface for QuickBooks OAuth authentication in Caskr.Server/Services/IQuickBooksAuthService.cs. This interface will define the contract for OAuth 2.0 authentication flow with QuickBooks Online. Include methods: 1) Task<string> GetAuthorizationUrlAsync(int companyId, string redirectUri) - generates OAuth URL for user authorization, 2) Task<OAuthTokenResponse> HandleCallbackAsync(string code, string realmId, int companyId) - exchanges authorization code for access/refresh tokens, 3) Task<OAuthTokenResponse> RefreshTokenAsync(int companyId) - refreshes expired access token, 4) Task RevokeAccessAsync(int companyId) - disconnects QuickBooks integration. Create supporting DTOs: OAuthTokenResponse (AccessToken, RefreshToken, ExpiresIn, RealmId). Add XML documentation comments explaining OAuth flow, token expiration (tokens expire in 1 hour, refresh tokens in 100 days), and security considerations."
P1-Critical,Financial Integration,QuickBooks Online Integration,FIN-005,Implement QuickBooks OAuth service,Backend Service,5,2,FIN-002|FIN-003|FIN-004,"- QuickBooksAuthService implements IQuickBooksAuthService
- OAuth 2.0 flow implemented correctly
- Tokens encrypted before database storage using Data Protection API
- Refresh token logic handles expiration
- Error handling for OAuth failures
- Integration tested with QuickBooks sandbox","Implement QuickBooksAuthService.cs in Caskr.Server/Services/. This service orchestrates OAuth 2.0 authentication with QuickBooks Online using the Intuit SDK. Implementation requirements: 1) Inject IConfiguration to read QBO client ID/secret from appsettings, CaskrDbContext for database access, IDataProtectionProvider for token encryption. 2) GetAuthorizationUrlAsync: Use OAuth2Client from Intuit SDK to generate authorization URL with required scopes (com.intuit.quickbooks.accounting). 3) HandleCallbackAsync: Exchange authorization code for tokens, encrypt access_token and refresh_token using Data Protection API, save to accounting_integrations table with company_id and realm_id. 4) RefreshTokenAsync: Check if token expired (compare created_at + expires_in with current time), use refresh token to get new access token, update database. 5) RevokeAccessAsync: Call Intuit revoke endpoint, mark integration as inactive. Include comprehensive error handling for network failures, invalid tokens, and QuickBooks API errors. Log all operations using ILogger for debugging."
P1-Critical,Financial Integration,QuickBooks Online Integration,FIN-006,Create QuickBooks OAuth controller endpoints,API Route,3,2,FIN-005,"- POST /api/accounting/quickbooks/connect - returns auth URL
- GET /api/accounting/quickbooks/callback - handles OAuth callback
- POST /api/accounting/quickbooks/disconnect - revokes access
- GET /api/accounting/quickbooks/status - checks connection status
- All endpoints require authentication
- Proper error responses (400, 401, 500)","Create QuickBooksController.cs in Caskr.Server/Controllers/ extending AuthorizedApiControllerBase (ensures user authentication). Implement OAuth endpoints: 1) POST /api/accounting/quickbooks/connect - accepts company_id, calls GetAuthorizationUrlAsync, returns {authUrl: string} for frontend redirect. 2) GET /api/accounting/quickbooks/callback?code=xxx&realmId=xxx&state=companyId - handles OAuth callback from QuickBooks, extracts code and realmId, calls HandleCallbackAsync, redirects to frontend success page. 3) POST /api/accounting/quickbooks/disconnect - accepts company_id, calls RevokeAccessAsync, returns 200 OK. 4) GET /api/accounting/quickbooks/status - accepts company_id, queries accounting_integrations table, returns {connected: bool, realmId: string, connectedAt: datetime}. Add proper error handling: 400 for invalid input, 401 for unauthorized, 500 for OAuth failures. Add XML documentation and [ProducesResponseType] attributes for Swagger. Validate user has permission to access the company_id before any operation."
P1-Critical,Financial Integration,QuickBooks Online Integration,FIN-007,Create chart of accounts mapping UI,User Interface,5,3,FIN-006,"- React component: AccountingSettingsPage.tsx
- Displays current QBO connection status
- Connect/Disconnect buttons
- Chart of accounts mapping table (Caskr Account → QBO Account)
- Dropdown to select QBO accounts from API
- Save mappings button
- Loading and error states","Create AccountingSettingsPage.tsx in caskr.client/src/pages/. This page allows users to connect QuickBooks and map chart of accounts. UI requirements: 1) Header showing connection status (Connected/Disconnected, realm ID, connected date). 2) If disconnected: 'Connect QuickBooks' button that calls POST /api/accounting/quickbooks/connect and redirects to returned authUrl. 3) If connected: 'Disconnect' button with confirmation dialog. 4) Chart of accounts mapping section: Table with columns [Caskr Account Type | QBO Account | Actions]. Display all CaskrAccountType enum values (COGS, WIP, Finished Goods, Raw Materials, Barrels, Excise Tax Payable, Revenue, etc.). For each row, show a searchable dropdown populated from GET /api/accounting/quickbooks/accounts (fetches QBO chart of accounts). Allow user to map Caskr account types to QBO account IDs. 5) 'Save Mappings' button calls POST /api/accounting/quickbooks/mappings. Use existing Caskr component patterns (see OrdersPage.tsx, Dashboard.tsx). Show loading spinner during API calls, error toasts for failures. Use Redux to store connection status if needed."
P1-Critical,Financial Integration,QuickBooks Online Integration,FIN-008,Create QBO chart of accounts sync service,Backend Service,3,3,FIN-005,"- IQuickBooksDataService interface created
- GetChartOfAccountsAsync() method implemented
- Fetches accounts from QBO API
- Caches results for 1 hour
- Returns list of QBOAccount (Id, Name, AccountType, Active)","Create IQuickBooksDataService interface and implementation in Caskr.Server/Services/. This service fetches data from QuickBooks Online using authenticated API calls. Primary method: Task<List<QBOAccount>> GetChartOfAccountsAsync(int companyId). Implementation: 1) Retrieve access token from accounting_integrations table for company_id. 2) Check if token is expired, call RefreshTokenAsync if needed. 3) Create ServiceContext from Intuit SDK using access token and realm_id. 4) Query QBO API: QueryService<Account>.ExecuteIdsQuery(""SELECT * FROM Account WHERE Active = true""). 5) Map Intuit Account objects to QBOAccount DTO (Id, Name, AccountType, AccountSubType, Active). 6) Cache results in memory (IMemoryCache) for 1 hour to reduce API calls. 7) Handle QBO API errors (rate limits, invalid tokens, network failures) with appropriate exceptions. Create QBOAccount.cs DTO model. Inject IMemoryCache, CaskrDbContext, IQuickBooksAuthService. Log all API calls for debugging."
P1-Critical,Financial Integration,QuickBooks Online Integration,FIN-009,Create API endpoint to fetch QBO accounts,API Route,2,3,FIN-008,"- GET /api/accounting/quickbooks/accounts endpoint
- Returns list of QBO accounts
- Requires company_id parameter
- Validates user has access to company
- Returns 200 with account list or 404 if not connected","Add endpoint to QuickBooksController: GET /api/accounting/quickbooks/accounts?companyId={id}. This endpoint is called by the frontend mapping UI to populate dropdowns. Implementation: 1) Validate companyId parameter is provided. 2) Verify current user has access to this company (check user.CompanyId matches or user is admin). 3) Check if QuickBooks is connected for this company (query accounting_integrations). 4) If not connected, return 404 with error message 'QuickBooks not connected for this company'. 5) Call quickBooksDataService.GetChartOfAccountsAsync(companyId). 6) Return 200 with JSON array of accounts [{id, name, accountType, active}]. Add error handling for QBO API failures, return 500 with user-friendly message. Add [Authorize] attribute, XML documentation, and Swagger response types. Consider adding optional query parameter ?refresh=true to bypass cache."
P1-Critical,Financial Integration,QuickBooks Online Integration,FIN-010,Create account mapping save endpoint,API Route,3,3,FIN-002|FIN-009,"- POST /api/accounting/quickbooks/mappings endpoint
- Accepts array of mappings {caskrAccountType, qboAccountId}
- Validates all QBO account IDs exist
- Upserts mappings to chart_of_accounts_mapping table
- Returns 200 with saved mappings","Add endpoint POST /api/accounting/quickbooks/mappings to QuickBooksController. Request body: {companyId: int, mappings: [{caskrAccountType: string, qboAccountId: string, qboAccountName: string}]}. Implementation: 1) Validate companyId and user access. 2) Validate all caskrAccountType values are valid enum members. 3) For each mapping, check if QBO account ID exists by calling GetChartOfAccountsAsync (or cache lookup). 4) Delete existing mappings for this company: DELETE FROM chart_of_accounts_mapping WHERE company_id = {companyId}. 5) Insert new mappings in batch using EF Core AddRange. 6) Save changes with dbContext.SaveChangesAsync(). 7) Return 200 with saved mappings array. Add validation: each CaskrAccountType should be mapped exactly once (no duplicates). Return 400 if validation fails with specific error (e.g., 'COGS account must be mapped'). Log mapping changes for audit trail."
P1-Critical,Financial Integration,QuickBooks Online Integration,FIN-011,Create invoice sync service interface,Backend Service,2,4,None,"- IQuickBooksInvoiceSyncService interface
- Methods: SyncInvoiceToQBO(), SyncPaymentToQBO(), SyncAllInvoices()
- Event handlers for invoice creation in Caskr
- Returns sync status and QBO invoice ID","Create IQuickBooksInvoiceSyncService interface in Caskr.Server/Services/. This service will synchronize invoices from Caskr to QuickBooks Online. Methods: 1) Task<InvoiceSyncResult> SyncInvoiceToQBOAsync(int invoiceId) - syncs single invoice to QBO, creates customer if doesn't exist, creates invoice in QBO, records sync in accounting_sync_logs. 2) Task<PaymentSyncResult> SyncPaymentToQBOAsync(int paymentId) - syncs payment record to QBO. 3) Task<BatchSyncResult> SyncAllPendingAsync(int companyId) - syncs all invoices with sync_status = Pending. Create DTOs: InvoiceSyncResult (Success, QBOInvoiceId, ErrorMessage), PaymentSyncResult, BatchSyncResult (SuccessCount, FailureCount, Errors[]). Interface should support both immediate sync (when invoice created) and batch sync (nightly job). Document that sync is unidirectional (Caskr → QBO) initially, bidirectional sync is future enhancement."
P1-Critical,Financial Integration,QuickBooks Online Integration,FIN-012,Implement invoice sync to QuickBooks,Backend Service,8,4,FIN-008|FIN-011,"- Invoice entity mapped to QBO Invoice object
- Customer auto-created in QBO if not exists
- Line items mapped correctly
- Tax handling implemented
- Sync status recorded in accounting_sync_logs
- Retry logic for transient failures
- Idempotent (doesn't create duplicates)","Implement QuickBooksInvoiceSyncService in Caskr.Server/Services/. Complex implementation with multiple steps: 1) Fetch invoice from Caskr database with all related data (customer, line items, taxes). 2) Check if invoice already synced (query accounting_sync_logs for this invoice_id with status = Success). If synced, return existing QBO invoice ID. 3) Check if customer exists in QBO (query by email or name). If not, create customer in QBO using Customer object from Intuit SDK. 4) Map Caskr invoice to QBO Invoice object: CustomerRef (QBO customer ID), TxnDate, Line items (Description, Amount, SalesItemLineDetail with account from chart_of_accounts_mapping), TxnTaxDetail (tax lines). 5) Create invoice in QBO using DataService.Add<Invoice>(). 6) Record sync in accounting_sync_logs (invoice_id, QBO invoice ID, status = Success, synced_at = now). 7) Error handling: For transient failures (network, rate limit), retry up to 3 times with exponential backoff. For permanent failures (invalid data), log error and mark status = Failed with error message. 8) Return InvoiceSyncResult. Use ILogger extensively for debugging. Make sync idempotent by checking accounting_sync_logs before creating."
P1-Critical,Financial Integration,QuickBooks Online Integration,FIN-013,Add invoice sync trigger to order completion,Backend Integration,3,4,FIN-012,"- When order status changes to 'Completed', invoice sync triggered
- Domain event or service call pattern
- Sync happens asynchronously (background job)
- Failures don't block order completion","Integrate invoice sync into the order completion workflow. Currently orders are managed in OrdersController and OrdersService. Add invoice sync trigger: 1) In OrdersService.CompleteOrderAsync (or similar method), after order status update to 'Completed', call invoiceSyncService.SyncInvoiceToQBOAsync(order.InvoiceId) if QuickBooks is connected. 2) Make sync call non-blocking: Either use Task.Run() or better, queue sync job to background service (create IBackgroundTaskQueue if not exists). 3) Check if company has QuickBooks enabled before attempting sync (query accounting_integrations WHERE company_id = order.CompanyId AND is_active = true). 4) Handle sync failures gracefully: if sync fails, log error but don't prevent order completion. User can retry sync manually from UI. 5) Emit domain event (OrderCompletedEvent) that QuickBooksInvoiceSyncService subscribes to (event-driven pattern). This decouples order logic from accounting sync. Consider using MediatR library for event handling if not already in use. Update OrdersService to inject IQuickBooksInvoiceSyncService or IBackgroundTaskQueue."
P1-Critical,Financial Integration,QuickBooks Online Integration,FIN-014,Create manual invoice sync UI button,User Interface,2,5,FIN-012,"- 'Sync to QuickBooks' button on invoice detail page
- Shows sync status (Pending, Syncing, Success, Failed)
- Displays QBO invoice ID if synced
- Error message if sync failed
- Retry button for failed syncs","Add QuickBooks sync UI to invoice/order detail page. In the existing order detail modal or page (OrderActionsModal.tsx or similar), add QuickBooks sync section: 1) Check if company has QuickBooks connected (fetch from Redux state or API). 2) Display sync status badge: Grey 'Not Synced' (no sync log), Yellow 'Syncing' (status = InProgress), Green 'Synced to QuickBooks' (status = Success), Red 'Sync Failed' (status = Failed). 3) If status = Success, display 'QBO Invoice #: {qboInvoiceId}' with link to QuickBooks (https://app.qbo.intuit.com/app/invoice?txnId={id}). 4) If not synced or failed, show 'Sync to QuickBooks' button. On click, call POST /api/accounting/quickbooks/sync-invoice with {invoiceId}. Show loading spinner during sync. 5) If failed, display error message below button (from accounting_sync_logs.error_message). Add 'Retry' button for failed syncs. Use existing Caskr styling patterns. Consider adding batch sync button on invoices list page to sync multiple invoices at once."
P1-Critical,Financial Integration,QuickBooks Online Integration,FIN-015,Create manual sync API endpoint,API Route,2,5,FIN-012,"- POST /api/accounting/quickbooks/sync-invoice
- Accepts invoiceId
- Validates user access to invoice
- Calls invoice sync service
- Returns sync result with QBO invoice ID or error","Add endpoint to QuickBooksController: POST /api/accounting/quickbooks/sync-invoice. Request body: {invoiceId: int}. Implementation: 1) Validate invoiceId exists in database. 2) Verify current user has access to this invoice (check invoice.CompanyId matches user.CompanyId). 3) Check QuickBooks is connected for this company. 4) Call invoiceSyncService.SyncInvoiceToQBOAsync(invoiceId). 5) Return result: {success: bool, qboInvoiceId: string?, errorMessage: string?}. If sync is already in progress (status = InProgress in accounting_sync_logs and synced_at within last 5 minutes), return 409 Conflict with message 'Sync already in progress'. Add rate limiting to prevent abuse (max 10 sync requests per minute per company). Return appropriate HTTP status codes: 200 for success, 400 for invalid invoice, 404 for not found, 409 for conflict, 500 for sync failure."
P1-Critical,Financial Integration,QuickBooks Online Integration,FIN-016,Create COGS tracking for batch completion,Backend Service,5,5,FIN-010,"- When batch is completed, calculate total COGS
- Journal entry created in QBO
- Debits: COGS account (from mapping)
- Credits: WIP account (from mapping)
- Amount: sum of all input costs (grain, barrels, labor)
- Journal entry synced to QBO","Implement cost of goods sold (COGS) tracking for distillery batches. When a batch is completed, create a journal entry in QuickBooks to move costs from Work in Progress (WIP) to COGS. Implementation in new service: IQuickBooksCostTrackingService. Method: Task<JournalEntrySyncResult> RecordBatchCOGSAsync(int batchId). Steps: 1) Fetch batch from database with all cost components (input materials from orders, barrel costs, labor if tracked). 2) Sum total batch cost. 3) Fetch chart of accounts mappings for COGS and WIP accounts (query chart_of_accounts_mapping WHERE caskr_account_type IN ('COGS', 'WIP')). 4) Create QBO JournalEntry object with two lines: Debit to COGS account (total cost), Credit to WIP account (total cost). 5) Include description: 'Batch {batchId} completion - {batch.Name}'. 6) Post to QBO using DataService.Add<JournalEntry>(). 7) Record in accounting_sync_logs (entity_type = 'Batch', entity_id = batchId, sync_status = Success). Integrate into batch completion workflow similar to invoice sync. This is critical for accurate financial reporting in QuickBooks."
P1-Critical,Financial Integration,QuickBooks Online Integration,FIN-017,Create settings page for sync preferences,User Interface,3,6,FIN-007,"- AccountingSyncPreferences.tsx component
- Toggle: Auto-sync invoices on order completion
- Toggle: Auto-sync COGS on batch completion
- Sync frequency dropdown (Immediate, Hourly, Daily)
- Test connection button
- Save preferences button","Create accounting sync preferences UI in AccountingSettingsPage.tsx (extend existing page from FIN-007 or create new section). Settings to configure: 1) Auto-sync invoices: Toggle switch, when enabled, invoices sync to QBO immediately on order completion. When disabled, manual sync only. 2) Auto-sync COGS: Toggle for automatic batch COGS journal entries. 3) Sync frequency: Dropdown with options [Immediate, Hourly, Daily, Manual]. Determines when background sync job runs. 4) Test Connection button: Calls GET /api/accounting/quickbooks/test to verify OAuth tokens are valid and refresh if needed. Shows success/failure toast. 5) Save button: Calls POST /api/accounting/quickbooks/preferences with {companyId, autoSyncInvoices, autoSyncCOGS, syncFrequency}. Store preferences in new table: accounting_sync_preferences. Use React useState for form state, handle loading and error states. Display current preferences on page load (GET /api/accounting/quickbooks/preferences)."
P1-Critical,Financial Integration,QuickBooks Online Integration,FIN-018,Implement background sync scheduler,Backend Service,5,6,FIN-012|FIN-016,"- Background job service using IHostedService
- Runs based on sync frequency preference
- Syncs all pending invoices and COGS entries
- Logs all sync operations
- Handles failures gracefully (retries, alerting)","Create background job for periodic QuickBooks sync. Implement QuickBooksSyncHostedService : IHostedService, IDisposable in Caskr.Server/Services/BackgroundJobs/. This service runs continuously and syncs pending items based on company preferences. Implementation: 1) In ExecuteAsync, run infinite loop with cancellation token support. 2) Query all companies with QuickBooks connected (accounting_integrations WHERE is_active = true). 3) For each company, fetch sync preferences (accounting_sync_preferences). 4) Based on sync_frequency and last_sync_at, determine if sync is due. 5) Query pending sync items: SELECT * FROM accounting_sync_logs WHERE company_id = {id} AND sync_status IN ('Pending', 'Failed') AND retry_count < 3. 6) Call SyncInvoiceToQBOAsync for each pending invoice, SyncBatchCOGSAsync for each pending batch. 7) Update accounting_sync_logs with results. 8) Sleep for interval based on frequency (1 hour for Hourly, 24 hours for Daily). Use ILogger to log all operations. Use IServiceScopeFactory to create scoped services (DbContext). Register service in Program.cs: builder.Services.AddHostedService<QuickBooksSyncHostedService>(). Handle exceptions gracefully, don't crash the service."
P1-Critical,Financial Integration,QuickBooks Online Integration,FIN-019,Create sync history and logs UI,User Interface,3,6,FIN-018,"- AccountingSyncHistory.tsx page
- Table showing all sync operations
- Columns: Date, Entity Type, Entity ID, Status, QBO ID, Error
- Filters: Status, Date range, Entity type
- Pagination
- Retry failed syncs button","Create sync history page to view all QuickBooks sync operations. New page: AccountingSyncHistoryPage.tsx. Implementation: 1) Fetch sync logs from GET /api/accounting/quickbooks/sync-logs?companyId={id}&status={status}&entityType={type}&page={page}&limit={limit}. Backend endpoint queries accounting_sync_logs with filters and pagination. 2) Display table with columns: [Synced At | Entity Type (Invoice, Batch, Payment) | Entity ID (clickable link to entity) | Status (badge with color) | QBO ID | Error Message | Actions]. 3) Status badges: Grey for Pending, Yellow for InProgress, Green for Success, Red for Failed. 4) Filters: Status dropdown (All, Success, Failed, Pending), Entity type dropdown, Date range picker. 5) For failed syncs, show 'Retry' button that calls POST /api/accounting/quickbooks/sync-invoice or sync-batch. 6) Show 'View in QuickBooks' link for successful syncs (opens QBO in new tab). 7) Add export to CSV button for audit purposes. Use existing table component patterns from OrdersPage.tsx or BarrelsPage.tsx. Add pagination controls at bottom."
P1-Critical,Financial Integration,QuickBooks Online Integration,FIN-020,Write integration tests for QBO sync,Testing,5,7,All FIN tasks,"- Integration tests for OAuth flow
- Tests for invoice sync (success and failure cases)
- Tests for COGS journal entry creation
- Tests for account mapping
- Tests use QBO sandbox environment
- All tests pass with >90% coverage","Create comprehensive integration tests for QuickBooks integration. Test file: Caskr.Server.Tests/Integration/QuickBooksIntegrationTests.cs. Use xUnit testing framework (existing in project). Tests to implement: 1) OAuth flow test: Mock OAuth callback, verify tokens saved to database encrypted. 2) Chart of accounts fetch test: Mock QBO API response, verify accounts fetched and cached. 3) Invoice sync success test: Create test invoice in database, mock QBO API success response, verify invoice synced and accounting_sync_logs updated. 4) Invoice sync failure test: Mock QBO API error (e.g., invalid customer), verify error logged and status = Failed. 5) COGS journal entry test: Create test batch with costs, verify journal entry created with correct debit/credit accounts. 6) Account mapping test: Create mappings, verify fetched correctly. 7) Duplicate sync test: Sync same invoice twice, verify second sync returns existing QBO ID (idempotency). Use Moq library for mocking IQuickBooksDataService, IQuickBooksAuthService. Use InMemory database for testing. Consider creating actual test in QBO sandbox if possible. Aim for >90% code coverage on all QuickBooks services."
P1-Critical,TTB Compliance,Monthly Report Automation,TTB-001,Research TTB Form 5110.28 requirements,Research & Analysis,3,1,None,"- Documentation of all fields in Form 5110.28
- Mapping of form fields to Caskr data model
- Calculation formulas for production operations
- Edge cases documented (e.g., losses, gains, transfers)","Research and document TTB Form 5110.28 (Monthly Report of Processing Operations). This is the primary monthly compliance report for distilled spirits plants. Download official form from TTB.gov (https://www.ttb.gov/forms/f511028.pdf). Create documentation file: docs/TTB_FORM_5110_28_MAPPING.md. Document: 1) All form fields with descriptions and data types. 2) Mapping to Caskr database tables (Orders, Batches, Barrels, Transfers, etc.). 3) Calculation formulas: Opening inventory (from previous month closing), Production this month (sum of completed batches), Transfers in, Transfers out, Losses (evaporation, spillage), Gains (rare), Closing inventory (opening + production + transfers in - transfers out - losses). 4) Different sections for spirits <190 proof, >=190 proof (neutral spirits), wine, etc. 5) Units: Wine gallons vs proof gallons conversion. 6) Edge cases: How to handle in-progress batches, transfers between bonded premises, tax determinations. 7) Required attachments and supporting documentation. This research informs database schema updates and calculation logic."
P1-Critical,TTB Compliance,Monthly Report Automation,TTB-002,Update database schema for TTB tracking,Database Schema,5,1,TTB-001,"- New table: ttb_monthly_reports (id, company_id, report_month, report_year, status, submitted_at, ttb_confirmation_number)
- New table: ttb_inventory_snapshots (id, company_id, snapshot_date, product_type, proof_gallons, wine_gallons)
- New table: ttb_transactions (id, company_id, transaction_date, transaction_type, product_type, proof_gallons, wine_gallons, related_entity_id)
- Indexes on report_month, report_year, company_id","Create database migration for TTB compliance tracking. File: Database/initdb.d/07-migration-ttb-compliance.sql. Create tables: 1) ttb_monthly_reports: Stores generated reports (id, company_id, report_month (1-12), report_year, status (Draft, Submitted, Approved), generated_at, submitted_at, ttb_confirmation_number, pdf_path, created_by_user_id). 2) ttb_inventory_snapshots: Daily inventory snapshots for audit trail (id, company_id, snapshot_date, product_type (Whiskey, Vodka, etc.), spirits_type (Under190Proof, Neutral, Wine), proof_gallons DECIMAL(12,2), wine_gallons DECIMAL(12,2), tax_status (Bonded, TaxPaid, Export)). 3) ttb_transactions: All TTB-relevant transactions (id, company_id, transaction_date, transaction_type ENUM(Production, Transfer_In, Transfer_Out, Loss, Gain, TaxDetermination, Destruction), product_type, spirits_type, proof_gallons, wine_gallons, source_entity_type (Batch, Barrel, Transfer), source_entity_id, notes TEXT). Add indexes on (company_id, report_month, report_year), (company_id, snapshot_date), (company_id, transaction_date). Add foreign keys to companies table."
P1-Critical,TTB Compliance,Monthly Report Automation,TTB-003,Create C# models for TTB entities,Backend Model,3,2,TTB-002,"- TtbMonthlyReport.cs entity
- TtbInventorySnapshot.cs entity
- TtbTransaction.cs entity
- Enums: TtbReportStatus, TtbTransactionType, TtbSpiritsType, TtbTaxStatus
- Models added to DbContext","Create entity models for TTB compliance in Caskr.Server/Models/. Files to create: 1) TtbMonthlyReport.cs with properties (Id, CompanyId, ReportMonth, ReportYear, Status, GeneratedAt, SubmittedAt, TtbConfirmationNumber, PdfPath, CreatedByUserId). Add navigation property to Company, User. 2) TtbInventorySnapshot.cs (Id, CompanyId, SnapshotDate, ProductType, SpiritsType, ProofGallons, WineGallons, TaxStatus). 3) TtbTransaction.cs (Id, CompanyId, TransactionDate, TransactionType, ProductType, SpiritsType, ProofGallons, WineGallons, SourceEntityType, SourceEntityId, Notes). Create enums: TtbReportStatus (Draft, Submitted, Approved, Rejected), TtbTransactionType (Production, TransferIn, TransferOut, Loss, Gain, TaxDetermination, Destruction, Bottling), TtbSpiritsType (Under190Proof, Neutral190OrMore, Alcohol, Wine), TtbTaxStatus (Bonded, TaxPaid, Export, TaxFree). Update CaskrDbContext.cs to include DbSet<TtbMonthlyReport>, DbSet<TtbInventorySnapshot>, DbSet<TtbTransaction>. Configure table names using snake_case (ttb_monthly_reports). Add validation attributes ([Required], [Range(1,12)] for month)."
P1-Critical,TTB Compliance,Monthly Report Automation,TTB-004,Create transaction logging service,Backend Service,5,2,TTB-003,"- ITtbTransactionLogger interface
- Methods to log all TTB-relevant events
- LogProduction(), LogTransfer(), LogLoss(), etc.
- Automatically calculates proof gallons from ABV and volume
- Integrates with existing batch/barrel/order services","Create ITtbTransactionLogger interface and TtbTransactionLoggerService in Caskr.Server/Services/. This service logs all transactions relevant to TTB reporting. Interface methods: 1) Task LogProductionAsync(int batchId, DateTime productionDate) - logs completed batch as Production transaction. 2) Task LogTransferInAsync(int transferId) - logs incoming transfer. 3) Task LogTransferOutAsync(int transferId) - logs outgoing transfer. 4) Task LogLossAsync(int barrelId, decimal proofGallons, string reason) - logs evaporation or spillage loss. 5) Task LogTaxDeterminationAsync(int orderId) - logs bottling and tax payment. Implementation: For each method, 1) Fetch relevant entity (batch, barrel, transfer, order) from database. 2) Calculate proof gallons: proofGallons = volume_gallons * (ABV / 100). Calculate wine gallons = volume_gallons. 3) Determine product_type from batch/barrel metadata. 4) Create TtbTransaction record with transaction_type, date, proof/wine gallons, source entity reference. 5) Save to database. Add helper method: CalculateProofGallons(decimal volumeGallons, decimal abv). Inject CaskrDbContext, ILogger. This service is called by existing services (BatchesService, BarrelsService, TransfersService, OrdersService) when TTB-relevant events occur."
P1-Critical,TTB Compliance,Monthly Report Automation,TTB-005,Integrate transaction logging into batch service,Backend Integration,3,3,TTB-004,"- BatchesService calls TTB transaction logger on batch completion
- Production transaction logged with correct date and volume
- No errors in existing batch workflows
- Backwards compatible (works if TTB not enabled)","Integrate TTB transaction logging into existing batch completion workflow. In Caskr.Server/Services/BatchesService.cs (or similar), find the method that completes a batch (e.g., CompleteBatchAsync). After batch status is updated to 'Completed', add TTB logging: 1) Inject ITtbTransactionLogger into BatchesService constructor. 2) After batch.Status = BatchStatus.Completed, call await ttbTransactionLogger.LogProductionAsync(batch.Id, DateTime.UtcNow). 3) Wrap in try-catch to prevent TTB logging failures from blocking batch completion. Log errors but don't throw. 4) Check if company has TTB compliance enabled before logging (query company settings or check if ttb_monthly_reports exist for company). Only log if enabled. This ensures all production is tracked for TTB reporting without changing existing batch workflows. Similar integration needed in BarrelsService for barrel fill/dump events, TransfersService for transfer events, OrdersService for bottling/tax events. For this task, focus only on BatchesService integration. Other services will be separate tasks."
P1-Critical,TTB Compliance,Monthly Report Automation,TTB-006,Create inventory snapshot scheduler,Backend Service,5,3,TTB-003,"- Daily scheduled job (runs at midnight)
- Snapshots current inventory by product type and spirits type
- Calculates proof gallons and wine gallons for all barrels
- Saves to ttb_inventory_snapshots table
- Can backfill historical snapshots","Create background service for daily inventory snapshots. File: Caskr.Server/Services/BackgroundJobs/TtbInventorySnapshotService.cs. Implements IHostedService. This service runs daily at midnight and captures inventory state for TTB reporting. Implementation: 1) In ExecuteAsync, calculate next midnight, sleep until then. 2) Query all companies with TTB enabled. 3) For each company, query all active barrels (status != Sold, != Emptied). 4) Group barrels by (product_type, spirits_type, tax_status). For each group, sum proof_gallons and wine_gallons. 5) Insert snapshot records: INSERT INTO ttb_inventory_snapshots (company_id, snapshot_date, product_type, spirits_type, proof_gallons, wine_gallons, tax_status) VALUES (...). Use CURRENT_DATE for snapshot_date. 6) Log snapshot creation. 7) Repeat daily. Add method: Task BackfillSnapshotsAsync(int companyId, DateTime startDate, DateTime endDate) for historical data. This generates snapshots for past dates by querying historical barrel states (may need barrel_history table or audit log). Register service: builder.Services.AddHostedService<TtbInventorySnapshotService>(). Critical for accurate monthly reporting."
P1-Critical,TTB Compliance,Monthly Report Automation,TTB-007,Create TTB report calculation service,Backend Service,8,4,TTB-004|TTB-006,"- ITtbReportCalculator interface
- CalculateMonthlyReport() method
- Returns structured report data (opening inventory, production, transfers, losses, closing inventory)
- Handles all spirits types and product types
- Validates data consistency (opening + changes = closing)","Create ITtbReportCalculator interface and TtbReportCalculatorService in Caskr.Server/Services/. This is the core calculation engine for Form 5110.28. Method: Task<TtbMonthlyReportData> CalculateMonthlyReportAsync(int companyId, int month, int year). Returns TtbMonthlyReportData DTO with all sections of Form 5110.28. Implementation: 1) Determine date range: startDate = first day of month, endDate = last day of month. 2) Get opening inventory: Query ttb_inventory_snapshots WHERE company_id = {id} AND snapshot_date = {first day of previous month}. If not exists, use sum of all transactions before startDate. 3) Get production: Query ttb_transactions WHERE company_id = {id} AND transaction_type = 'Production' AND transaction_date BETWEEN startDate AND endDate. Sum proof_gallons and wine_gallons by product_type and spirits_type. 4) Get transfers in: transaction_type = 'TransferIn'. 5) Get transfers out: transaction_type = 'TransferOut'. 6) Get losses: transaction_type = 'Loss'. 7) Calculate closing inventory: opening + production + transfers_in - transfers_out - losses. 8) Validate: closing inventory from calculation should match snapshot on last day of month (within tolerance of 0.01 gallons). If mismatch, log warning. Return TtbMonthlyReportData with all sections populated. Create DTO classes for each form section (ProductionSection, TransfersSection, etc.)."
P1-Critical,TTB Compliance,Monthly Report Automation,TTB-008,Create PDF generation for Form 5110.28,Backend Service,8,5,TTB-007,"- PDF template for Form 5110.28 (official TTB form)
- Service fills template with calculated data
- All fields populated correctly
- PDF saved to storage
- Returns file path and byte array","Create service to generate PDF for TTB Form 5110.28. Service: ITtbPdfGenerator, TtbPdfGeneratorService in Caskr.Server/Services/. This uses iText7 (already in project from FIN tasks). Method: Task<byte[]> GenerateForm5110_28Async(TtbMonthlyReportData reportData). Implementation: 1) Load PDF template from Forms/ttb_form_5110_28.pdf (download official form from TTB.gov and place in Forms directory). 2) Use iText7 to fill form fields (similar to existing LabelsService and TransfersService patterns). 3) Map reportData to form fields. Example fields: 'permit_number' (from Company.TtbPermitNumber), 'report_month', 'report_year', 'opening_inventory_proof_gallons', 'production_proof_gallons', 'transfers_in_proof_gallons', etc. Form has separate sections for different spirits types. 4) Fill all numeric fields formatted to 2 decimal places. 5) Include company information (name, address, permit number) from Company table. 6) Flatten form (make non-editable). 7) Save PDF to storage: Caskr.Server/Storage/TTBReports/{companyId}/{year}/{month}/Form_5110_28.pdf. Create directory if not exists. 8) Return byte array for download. Add comprehensive logging. Handle missing form fields gracefully (log warning if field not found in template)."
P1-Critical,TTB Compliance,Monthly Report Automation,TTB-009,Create TTB report generation endpoint,API Route,3,5,TTB-007|TTB-008,"- POST /api/ttb/reports/generate endpoint
- Accepts companyId, month, year
- Validates user has permission
- Generates report using calculator and PDF generator
- Saves TtbMonthlyReport record with status=Draft
- Returns PDF for download","Create TtbReportsController in Caskr.Server/Controllers/ extending AuthorizedApiControllerBase. Endpoint: POST /api/ttb/reports/generate. Request body: {companyId: int, month: int, year: int}. Implementation: 1) Validate month (1-12) and year (>= 2020). 2) Verify user has access to company (user.CompanyId == companyId or user is admin). 3) Check if report already exists: query TtbMonthlyReport WHERE company_id = {id} AND report_month = {month} AND report_year = {year}. If exists with status = Submitted or Approved, return 409 Conflict (can't regenerate submitted reports). If exists with status = Draft, delete and regenerate. 4) Call ttbReportCalculator.CalculateMonthlyReportAsync(companyId, month, year). 5) Call ttbPdfGenerator.GenerateForm5110_28Async(reportData). 6) Create TtbMonthlyReport record: company_id, report_month, report_year, status = Draft, generated_at = now, pdf_path = {path}. 7) Save to database. 8) Return File(pdf bytes, ""application/pdf"", $""Form_5110_28_{month}_{year}.pdf""). Add error handling for validation failures, missing data (e.g., no transactions for month), PDF generation errors. Add XML docs and Swagger attributes."
P1-Critical,TTB Compliance,Monthly Report Automation,TTB-010,Create TTB reports list UI,User Interface,5,6,TTB-009,"- TtbReportsPage.tsx component
- Table showing all generated reports by month/year
- Status indicators (Draft, Submitted, Approved)
- Generate new report button
- Download PDF button
- Submit to TTB button (future: actual submission)
- Filters by year and status","Create TTB reports page in caskr.client/src/pages/TtbReportsPage.tsx. This page displays all monthly reports for the company. UI: 1) Header with 'TTB Monthly Reports (Form 5110.28)' title. 2) 'Generate New Report' button that opens modal with month/year picker. On submit, calls POST /api/ttb/reports/generate and downloads PDF. 3) Reports table with columns: [Month/Year | Generated Date | Status | Actions]. Example row: 'October 2024 | 11/05/2024 | Draft | [Download PDF] [View] [Submit]'. 4) Status badges: Grey for Draft, Blue for Submitted, Green for Approved. 5) Actions: 'Download PDF' button calls GET /api/ttb/reports/{id}/download. 'View' button opens PDF in modal (iframe). 'Submit' button (future implementation, for now shows 'Manual submission required' message). 6) Filters: Year dropdown (current year and past 5 years), Status dropdown (All, Draft, Submitted, Approved). 7) Fetch reports from GET /api/ttb/reports?companyId={id}&year={year}&status={status}. Backend endpoint queries TtbMonthlyReport table with filters. Use existing table components from OrdersPage.tsx. Add loading states and error handling."
P1-Critical,TTB Compliance,Monthly Report Automation,TTB-011,Add TTB compliance navigation menu item,User Interface,1,6,TTB-010,"- New menu item: 'TTB Compliance' in main navigation
- Links to TtbReportsPage
- Icon (clipboard or government building)
- Only visible if user has TTB permission","Add TTB Compliance to main navigation menu. In caskr.client/src/components/Navigation.tsx (or Layout.tsx if menu is there), add new navigation item: 1) Label: 'TTB Compliance' or 'Compliance Reports'. 2) Icon: Use clipboard icon or government building icon (from react-icons or existing icon library). 3) Route: /ttb-reports (add route in App.tsx routing config: <Route path=""/ttb-reports"" element={<TtbReportsPage />} />). 4) Permission check: Only show menu item if user has TTB_COMPLIANCE permission (check user.permissions or user.role). May need to add permission to User model and seed data. 5) Position in menu: Place under 'Reports' section or create new 'Compliance' section. Follow existing menu styling and patterns. Update route protection in routing config to require authentication and TTB permission."
P1-Critical,TTB Compliance,Monthly Report Automation,TTB-012,Create Form 5110.40 support (Storage Operations),Backend Service,5,7,TTB-007,"- Extend calculator to support Form 5110.40
- Storage operations report (barrel aging, warehouse operations)
- Different calculation logic than 5110.28
- PDF generation for Form 5110.40
- Integrated into same reports page","Add support for TTB Form 5110.40 (Monthly Report of Storage Operations). Similar to Form 5110.28 but focused on storage/aging operations. Extend TtbReportCalculatorService: 1) Add method: Task<TtbForm5110_40Data> CalculateForm5110_40Async(int companyId, int month, int year). This calculates storage-specific metrics: Barrels in storage (opening), Barrels received this month, Barrels removed this month, Barrels in storage (closing), Proof gallons in aging (by warehouse location if multi-warehouse). 2) Query ttb_inventory_snapshots for opening/closing counts. 3) Query ttb_transactions for received (TransferIn, Production) and removed (TransferOut, Bottling). 4) Group by warehouse location if Company has multiple warehouses. 5) Download Form 5110.40 from TTB.gov, add to Forms directory. 6) Extend TtbPdfGeneratorService: Add method GenerateForm5110_40Async(TtbForm5110_40Data data). Fill form template with storage data. 7) Update TtbReportsController: Add optional parameter formType to generate endpoint. Default to 5110.28, support '5110.40'. 8) Update TtbMonthlyReport model: Add form_type column (ENUM: '5110_28', '5110_40'). This allows distilleries to generate both required monthly reports."
P1-Critical,TTB Compliance,Monthly Report Automation,TTB-013,Add automated report scheduling,Backend Service,5,7,TTB-009|TTB-012,"- Monthly scheduled job (runs on 1st of each month)
- Auto-generates previous month's reports
- Saves as Draft status for review
- Sends email notification to compliance officer
- Configurable per company (some want auto-gen, some don't)","Create background service for automatic monthly report generation. File: TtbAutoReportGeneratorService.cs implementing IHostedService. This service auto-generates reports on the 1st of each month for the previous month. Implementation: 1) In ExecuteAsync, calculate next 1st of month at 6:00 AM, sleep until then. 2) Query companies with auto_generate_ttb_reports = true (add column to companies table or create ttb_settings table). 3) For each company, generate previous month's reports: month = current month - 1, year = current year (handle January edge case). 4) Call ttbReportCalculator.CalculateMonthlyReportAsync and ttbPdfGenerator.GenerateForm5110_28Async. 5) Create TtbMonthlyReport record with status = Draft. 6) Send email notification to compliance officer (query users WHERE company_id = {id} AND role = 'Compliance' OR is_ttb_contact = true). Email subject: 'TTB Monthly Report Generated - Review Required'. Include link to report in email body. 7) Log all operations. 8) Repeat monthly. Add configuration: Allow companies to disable auto-generation or change schedule (some distilleries may want weekly drafts). Use IEmailService for notifications (may need to create if not exists). Register service in Program.cs."
P1-Critical,TTB Compliance,Monthly Report Automation,TTB-014,Create data validation and warnings,Backend Service,5,8,TTB-007,"- Report calculator validates data consistency
- Warnings for unusual values (e.g., losses >10%)
- Errors for missing required data
- Validation results stored with report
- UI displays validation warnings before submission","Add data validation to TTB report generation. Extend TtbReportCalculatorService to include validation: 1) Create ValidationResult class with properties: IsValid (bool), Errors (List<string>), Warnings (List<string>). 2) In CalculateMonthlyReportAsync, after calculations, run validations: Check opening + production + transfers_in - transfers_out - losses = closing (within 0.1% tolerance). If not, add error: 'Inventory reconciliation failed. Check transaction logs.' Check for reasonable loss percentage: losses / opening_inventory. If >15%, add warning: 'Loss percentage ({pct}%) is unusually high. Review loss entries.' Check for negative inventory values. If found, add error: 'Negative inventory detected for {product_type}. Check data.' Check if any required fields missing (e.g., no TTB permit number). Add error if missing. 3) Return ValidationResult along with TtbMonthlyReportData. 4) Update TtbMonthlyReport model: Add columns validation_errors (JSON), validation_warnings (JSON). 5) In generate endpoint, save validation results to database. If errors exist, set status = ValidationFailed instead of Draft. 6) Update UI: In TtbReportsPage, display validation errors/warnings. Show warning icon if warnings exist. Block submission if errors exist. Add 'View Validation Report' button that shows detailed error/warning list."
P1-Critical,TTB Compliance,Monthly Report Automation,TTB-015,Create manual transaction entry UI,User Interface,5,8,TTB-004,"- TtbTransactionsPage.tsx component
- Form to manually add transactions
- Fields: Date, Type, Product, Proof Gallons, Wine Gallons, Notes
- Table showing all transactions for a month
- Edit/Delete capabilities
- Used for corrections or manual entries","Create manual transaction entry page for TTB transactions. File: caskr.client/src/pages/TtbTransactionsPage.tsx. This allows users to manually add, edit, or delete TTB transactions (useful for corrections, non-automated events like manual losses). UI: 1) Header with month/year selector. 2) 'Add Transaction' button opens modal with form: Transaction Date (date picker), Transaction Type (dropdown: Production, Transfer In, Transfer Out, Loss, Gain, Tax Determination, Destruction), Product Type (dropdown from existing products), Spirits Type (dropdown: Under 190 Proof, Neutral, Wine), Proof Gallons (number input, 2 decimals), Wine Gallons (number input, 2 decimals), Notes (textarea). On submit, POST /api/ttb/transactions with form data. 3) Transactions table for selected month: Columns [Date | Type | Product | Spirits Type | Proof Gallons | Wine Gallons | Source | Notes | Actions]. Source column shows if transaction is auto-generated (e.g., 'Batch #123') or manual ('Manual Entry'). 4) Actions: Edit button (opens same modal pre-filled), Delete button (confirmation dialog, DELETE /api/ttb/transactions/{id}). 5) Summary footer showing totals: Total Production, Total Transfers In, Total Transfers Out, Total Losses for the month. 6) Export to CSV button. Backend endpoints: POST /api/ttb/transactions (create), PUT /api/ttb/transactions/{id} (update), DELETE /api/ttb/transactions/{id} (delete), GET /api/ttb/transactions?companyId={id}&month={m}&year={y} (list). Add permission check: only users with TTB_EDIT permission can add/edit/delete transactions."
P1-Critical,TTB Compliance,Monthly Report Automation,TTB-016,Add gauge record tracking,Backend Service,8,9,TTB-002,"- Gauge record for each barrel (required by TTB)
- Table: ttb_gauge_records (barrel_id, gauge_date, proof, temperature, proof_gallons_calculated)
- Automatic gauge creation on barrel fill
- Manual gauge entry support
- Gauge records linked to monthly reports","Implement gauge record tracking for TTB compliance. Gauge records document the proof and volume of spirits at time of fill, storage, and removal. Create table: ttb_gauge_records (id, barrel_id FK, gauge_date TIMESTAMP, gauge_type ENUM(Fill, Storage, Removal), proof DECIMAL(5,2), temperature DECIMAL(5,2), wine_gallons DECIMAL(10,2), proof_gallons DECIMAL(10,2), gauged_by_user_id FK, notes TEXT). Implementation: 1) Create entity model TtbGaugeRecord.cs with navigation properties to Barrel and User. 2) Create service: ITtbGaugeRecordService. Methods: CreateGaugeRecordAsync(int barrelId, GaugeType type, decimal proof, decimal temp, decimal wineGallons), GetGaugeRecordsForBarrelAsync(int barrelId). 3) Calculation: proof_gallons = wine_gallons * (proof / 100). Auto-adjust for temperature using TTB temperature-correction tables (complex but required for accuracy - may need lookup table). 4) Integration: In BarrelsService, when barrel is filled (status = Filled), automatically create Fill gauge record using batch ABV and volume. When barrel dumped (status = Emptied), create Removal gauge record. 5) Add manual gauge entry: Storage gauges are typically manual (monthly or quarterly inventory checks). Create UI for warehouse staff to enter gauge readings. 6) Link to reports: Include gauge records in Form 5110.28/5110.40 calculations for accurate proof gallons. This is critical for TTB audit compliance."
P1-Critical,TTB Compliance,Monthly Report Automation,TTB-017,Create excise tax calculation,Backend Service,5,9,TTB-016,"- Calculate federal excise tax on removed spirits
- Rate: $13.50 per proof gallon (or $13.34 for small distillers)
- Tax determination tracking in ttb_transactions
- Integration with accounting (if QuickBooks connected, post tax liability)
- Excise tax reports","Implement excise tax calculation for TTB compliance. Federal excise tax on distilled spirits is $13.50 per proof gallon (reduced rate of $13.34/proof gallon for first 100,000 proof gallons for eligible distillers under Craft Beverage Modernization Act). Create service: ITtbExciseTaxService. Methods: 1) Task<ExciseTaxCalculation> CalculateTaxAsync(int orderId) - calculates tax for bottled/removed spirits. Implementation: Fetch order with all barrels/batches. Sum total proof gallons removed. Determine applicable tax rate: Check if company is eligible for reduced rate (annual production < 2.25M proof gallons, no foreign ownership). Apply rate: $13.34 for first 100,000 PG, $13.50 for remainder. Calculate total tax due. 2) Task<TtbTransaction> RecordTaxDeterminationAsync(int orderId, ExciseTaxCalculation calc) - creates TtbTransaction with type = TaxDetermination. Includes proof gallons and calculated tax amount. 3) Integration with QuickBooks: If accounting integration enabled, create journal entry: Debit Excise Tax Expense (from chart of accounts mapping), Credit Excise Tax Payable. Amount = calculated tax. This keeps tax liability tracked in accounting system. 4) Create ExciseTaxReport (month/year) showing: Total proof gallons removed, Total tax due, Tax paid (if integrated with accounting), Outstanding tax liability. Required for TTB monthly reporting and payment. Store calculations in ttb_tax_determinations table (id, company_id, order_id, proof_gallons, tax_rate, tax_amount, determination_date, paid_date, payment_reference)."
P1-Critical,TTB Compliance,Monthly Report Automation,TTB-018,Create audit trail and history,Backend Service,3,10,All TTB tasks,"- Complete audit log for all TTB data changes
- Track who created/modified/deleted transactions
- Immutable once month is submitted
- Export audit trail to CSV for TTB inspections
- Timestamp all changes with UTC time","Implement comprehensive audit trail for TTB compliance. TTB audits require proving data integrity and who made changes. Create table: ttb_audit_logs (id, company_id, entity_type (TtbTransaction, TtbReport, GaugeRecord), entity_id, action (Create, Update, Delete), changed_by_user_id FK, change_timestamp TIMESTAMP, old_values JSONB, new_values JSONB, ip_address VARCHAR(45), user_agent TEXT). Implementation: 1) Create audit logging service: ITtbAuditLogger. Method: Task LogChangeAsync<T>(string action, T entity, T? oldEntity, int userId). 2) Integrate into all TTB services: In TtbTransactionLoggerService, TtbReportCalculatorService, TtbGaugeRecordService, after any Create/Update/Delete operation, call auditLogger.LogChangeAsync. Capture old and new values as JSON for comparison. 3) Implement immutability rule: Once TtbMonthlyReport has status = Submitted or Approved, prevent changes to any transactions for that month. In update/delete endpoints, check if related month's report is submitted. Return 403 Forbidden with message 'Cannot modify data for submitted reports. Contact administrator.' 4) Export functionality: Create endpoint GET /api/ttb/audit-trail?companyId={id}&startDate={date}&endDate={date} returns CSV with all changes. Include columns: Timestamp, User, Entity, Action, Details. 5) UI: Add 'Audit Trail' tab to TtbReportsPage showing recent changes. Display user-friendly change descriptions (e.g., 'John Doe added Loss transaction for 5.25 proof gallons on 10/15/2024'). Essential for compliance and internal controls."
P1-Critical,TTB Compliance,Monthly Report Automation,TTB-019,Create TTB submission workflow,Backend Service,5,10,TTB-014|TTB-018,"- Multi-step submission workflow: Draft → Review → Approved → Submitted
- Role-based approvals (e.g., Compliance Manager must approve)
- Email notifications at each step
- Lock report data after submission
- Track submission date and confirmation number","Implement submission workflow for TTB reports. Reports should go through review/approval before submission to TTB. Workflow states: Draft → PendingReview → Approved → Submitted → Archived. Implementation: 1) Update TtbMonthlyReport model: Add columns reviewed_by_user_id, reviewed_at, approved_by_user_id, approved_at. 2) Create state machine in TtbReportWorkflowService: Methods: SubmitForReviewAsync(int reportId, int userId) - changes status Draft → PendingReview, sends email to reviewers. ApproveReportAsync(int reportId, int userId) - requires role = ComplianceManager, changes status PendingReview → Approved, sends email to submitter. SubmitToTtbAsync(int reportId, string confirmationNumber) - changes status Approved → Submitted, locks all related data, records confirmation number from TTB. 3) Validation: Before moving to PendingReview, run validation (FIN-014). Block if errors exist. Before Approved → Submitted, ensure no validation errors and all required fields populated. 4) Notifications: Use IEmailService to send emails at each state transition. Email templates: review_requested.html, report_approved.html, submission_confirmed.html. 5) Data locking: When status = Submitted, prevent any changes to transactions for that month (see FIN-018). 6) UI: Add status badges and action buttons to reports page. 'Submit for Review' button (Draft → PendingReview), 'Approve' button (for ComplianceManager users), 'Mark as Submitted' button with modal to enter TTB confirmation number."
P1-Critical,TTB Compliance,Monthly Report Automation,TTB-020,Write comprehensive TTB documentation,Documentation,5,10,All TTB tasks,"- User guide for TTB compliance features
- How to generate monthly reports
- How to review and submit reports
- How to handle corrections
- FAQ for common TTB scenarios
- Admin guide for setup and configuration","Create comprehensive user documentation for TTB compliance features. File: docs/TTB_COMPLIANCE_USER_GUIDE.md. Document structure: 1) **Introduction**: Overview of TTB compliance requirements for distilleries, explanation of Forms 5110.28 and 5110.40. 2) **Setup**: How to enable TTB compliance, configure company TTB permit number, set up automatic report generation, assign compliance roles (who can review/approve reports). 3) **Daily Operations**: How TTB transactions are automatically logged (batch completion, transfers, bottling), when to manually add transactions (losses, corrections), gauge record entry for barrels. 4) **Monthly Reporting**: How to generate draft reports (auto or manual), how to review report data, understanding validation warnings, correcting errors before submission, approval workflow (submit for review → manager approves → submit to TTB). 5) **Submitting to TTB**: How to download final PDF, where to submit (TTB Pay.gov portal), how to enter confirmation number after submission, what happens after submission (data locked). 6) **Corrections and Amendments**: How to handle errors after submission, when to file amended reports, how to add manual transactions for prior periods. 7) **Audit Trail**: How to export audit logs for TTB inspections, understanding immutability rules. 8) **FAQ**: Common questions (What if my inventory doesn't reconcile?, How do I report evaporation losses?, What's the difference between proof gallons and wine gallons?). 9) **Troubleshooting**: Common errors and solutions. Include screenshots (mock-ups) of UI, step-by-step instructions, best practices. Format as markdown with table of contents."
P2-High,Advanced Reporting,Report Builder,REP-002,Create report query engine service,Backend Service,8,12,REP-001,"- Service executes dynamic reports based on template configuration
- Supports JOINs across multiple tables
- Applies filters, groupings, sorting dynamically
- Returns data in paginated format
- Performance optimized with query caching","Implement a dynamic report execution engine in Caskr.Server/Services/ReportingService.cs. This service generates SQL queries dynamically based on report templates. Interface: IReportingService with method Task<ReportResult> ExecuteReportAsync(int reportTemplateId, Dictionary<string, object> parameters). Implementation: 1) Fetch report template from database. 2) Parse data_sources JSON to determine which tables to query (e.g., ['barrels', 'batches', 'orders']). 3) Build SELECT clause from columns JSON (e.g., ['barrels.sku', 'batches.name', 'barrels.created_at']). 4) Build FROM clause with appropriate JOINs (use Entity Framework Core Include/ThenInclude or raw SQL). 5) Build WHERE clause from filters JSON combined with runtime parameters (e.g., {filter: 'barrels.status = @status AND barrels.created_at >= @startDate', parameters: {status: 'Aging', startDate: '2024-01-01'}}). Use parameterized queries to prevent SQL injection. 6) Apply GROUP BY from groupings JSON (e.g., 'GROUP BY batches.id'). 7) Apply ORDER BY from sort_order JSON. 8) Execute query using EF Core or Dapper for complex queries. 9) Apply pagination (LIMIT/OFFSET). 10) Return ReportResult DTO with {columns: [...], rows: [...], totalRows: int, executionTime: int}. Cache results for identical queries (5 min cache). Log slow queries (>2 sec). Security: Ensure user has access to company_id in all queries. This is complex - consider using a query builder library like Dynamic LINQ or SqlKata for safety and maintainability."
P2-High,Advanced Reporting,Report Builder,REP-003,Create 30 standard report templates,Data Seeding,8,13,REP-002,"- SQL seed data for 30 standard reports
- Categories: Financial (10), Inventory (10), Production (5), Compliance (5)
- Each report has: name, description, pre-configured filters, columns, groupings
- Reports tested with sample data","Create 30 standard report templates as seed data. File: Database/initdb.d/09-seed-standard-reports.sql. Reports to include: **Financial Reports (10)**: 1) Inventory Valuation by Batch (total value of aging inventory), 2) Cost of Goods Sold by Month (monthly COGS), 3) Revenue by Product Type, 4) Profit Margin by Batch, 5) Work in Progress Valuation, 6) Barrel Cost Analysis (cooper costs over time), 7) Aging Inventory Summary (value by age bracket), 8) Excise Tax Liability Report, 9) Monthly Production Costs, 10) Customer Revenue Ranking. **Inventory Reports (10)**: 1) Current Barrel Inventory by Status, 2) Barrel Aging Report (barrels by age range), 3) Warehouse Utilization by Location, 4) Low Stock Alert (products below threshold), 5) Barrel Movement History, 6) Inventory by Proof Range, 7) Batch Yield Analysis (compare expected vs actual), 8) Evaporation Loss Report (angels' share), 9) Barrels Due for Dumping (age threshold reached), 10) Multi-Warehouse Inventory Comparison. **Production Reports (5)**: 1) Monthly Production Volume (proof gallons produced), 2) Batch Efficiency Report (time from mash to barrel), 3) Equipment Utilization, 4) Quality Control Metrics, 5) Mash Bill Usage Analysis. **Compliance Reports (5)**: 1) TTB Monthly Summary (matches Form 5110.28), 2) Transfer Documentation Log, 3) Gauge Record Summary, 4) Tax Determination History, 5) Audit Trail Report. For each report, INSERT INTO report_templates with full JSON configuration. Test each report with sample data to ensure queries work correctly."
P2-High,Advanced Reporting,Report Builder,REP-004,Create report builder UI,User Interface,8,14,REP-003,"- ReportBuilderPage with list of available reports
- Filter selection UI (dynamic based on report template)
- Run report button, shows results in table
- Export to Excel/PDF/CSV
- Save custom filters as saved report","Create report builder UI in caskr.client/src/pages/ReportsPage.tsx. This page allows users to select, configure, and run reports. Implementation: 1) **Report selection**: Left sidebar with categorized report list (Financial, Inventory, Production, Compliance). Each category expandable with report names. Clicking report loads it in main area. Include search/filter for reports. 2) **Report configuration area**: Display selected report name and description. Show filter panel with inputs for each filter defined in template. Filters are dynamic based on report configuration: Date range filters (DateRangePicker), Status filters (multi-select checkboxes), Numeric filters (min/max inputs), Text filters (search input). Batch/Product filters (autocomplete). 3) **Run report button**: Primary button, calls POST /api/reports/execute with {reportTemplateId, filters: {...}}. Shows loading spinner during execution. 4) **Results display**: Table with columns from report definition. Sortable columns (click header to sort). Pagination controls. Summary footer if report includes totals. 5) **Export buttons**: Excel (calls GET /api/reports/{executionId}/export?format=xlsx, uses ExcelJS to generate file), PDF (uses jsPDF or server-side generation), CSV (simple comma-separated download). 6) **Save report**: 'Save as Favorite' button saves current filter configuration to saved_reports table. 'Saved Reports' tab shows user's saved reports with quick run links. 7) **Scheduled reports** (future): Option to schedule report to run monthly and email results. Use existing table components from OrdersPage. Consider adding chart visualization for financial reports (use Recharts library)."
P2-High,Advanced Reporting,Report Builder,REP-005,Create custom report builder UI,User Interface,8,15,REP-004,"- Drag-and-drop report builder interface
- Select data sources (tables)
- Select columns to include
- Configure filters, groupings, sorting
- Preview report before saving
- Save as custom report template","Create advanced report builder for power users to create custom reports. File: caskr.client/src/pages/CustomReportBuilderPage.tsx. This is a complex drag-and-drop UI builder. Implementation: 1) **Data source selection**: Step 1: Select tables to query from: Barrels, Batches, Orders, Tasks, Transfers, Products, MashBills, Companies. Multi-select checkboxes. System auto-detects JOIN relationships (e.g., Barrels → Batches via batch_id). 2) **Column selection**: Step 2: For each selected table, show available columns in left panel. Drag columns to 'Selected Columns' panel on right. Each column can be configured: Display name (alias), Aggregation function (SUM, AVG, COUNT, MIN, MAX for numeric columns), Formatting (date format, number decimals, currency). 3) **Filters configuration**: Step 3: Add filters panel. Button 'Add Filter' shows dropdown of all available columns. For each filter: Select column, Select operator (=, !=, >, <, >=, <=, IN, BETWEEN, LIKE, IS NULL), Enter value(s) - input type dynamic based on column type (date picker for dates, number input for numbers, text for strings). AND/OR logic between filters. 4) **Groupings**: Step 4: Drag columns to 'Group By' panel if aggregation needed. 5) **Sorting**: Step 5: Drag columns to 'Sort By' panel, choose ASC/DESC. 6) **Preview**: Button 'Preview Report' calls POST /api/reports/preview with current configuration (limit to 100 rows). Shows results in table. 7) **Save**: Form fields for report name, description, category. Button 'Save Custom Report' creates new report_template record. Report appears in standard reports list under 'Custom Reports' category. This is advanced functionality - consider using a library like React DnD (Drag and Drop). Alternatively, use a form-based approach instead of drag-and-drop for MVP."
P2-High,Warehouse Management,Multi-Warehouse Support,WH-004,Add multi-warehouse support to data model,Database Schema,3,18,WH-002,"- Company can have multiple warehouses
- Barrels track which warehouse they're in
- Orders can specify source warehouse
- Transfers between warehouses tracked
- Warehouse-specific capacity and utilization metrics","Extend database schema for multi-warehouse support. Currently Caskr assumes single warehouse per company. Changes needed: 1) warehouses table already created in WH-002. 2) Update barrels table: warehouse_id FK (already added in WH-002), Add index on warehouse_id. Update existing barrels: SET warehouse_id = (SELECT id FROM warehouses WHERE company_id = barrels.company_id LIMIT 1). Make warehouse_id NOT NULL after backfill. 3) Update orders table: Add fulfillment_warehouse_id FK (which warehouse will fulfill this order). 4) Create inter_warehouse_transfers table (id, from_warehouse_id FK, to_warehouse_id FK, transfer_date DATE, barrels_count INTEGER, proof_gallons DECIMAL(12,2), status ENUM('Pending', 'In_Transit', 'Completed'), initiated_by_user_id FK, completed_at, notes TEXT). Link barrels to transfers: barrel_transfers (id, barrel_id FK, transfer_id FK, transferred_at). 5) Create warehouse_capacity_snapshots (id, warehouse_id FK, snapshot_date DATE, total_capacity INTEGER, occupied_positions INTEGER, occupancy_percentage DECIMAL(5,2)). Daily snapshots for trending. 6) Update views and stored procedures to filter by warehouse_id where applicable. 7) Update Company model in C#: Add navigation property List<Warehouse> Warehouses. Migration file: Database/initdb.d/11-migration-multi-warehouse-support.sql. This enables large distilleries with multiple facilities to manage all inventory in one system."
P2-High,Warehouse Management,Multi-Warehouse Support,WH-005,Create warehouse management UI,User Interface,5,18,WH-004,"- Warehouse list page for company admins
- Create/edit/deactivate warehouse
- View capacity and occupancy stats
- Switch between warehouses in barrel list
- Warehouse filter in all relevant screens","Create warehouse management UI. File: caskr.client/src/pages/WarehousesPage.tsx. This page allows admins to configure warehouses. Implementation: 1) **Warehouse list**: Table showing all warehouses for company. Columns: [Name | Type | Location | Capacity | Occupancy | Status | Actions]. Example row: 'Rickhouse #1 | Rickhouse | Bardstown, KY | 5,000 barrels | 3,245 (65%) | Active | [Edit] [View] [Deactivate]'. Occupancy shown as progress bar (color: green <80%, orange 80-95%, red >95%). 2) **Create warehouse button**: Opens modal/form with fields: Warehouse Name (required), Warehouse Type (dropdown: Rickhouse, Palletized, Tank Farm, Outdoor), Address (full address), Total Capacity (integer, number of barrel positions), Dimensions (Length x Width x Height in feet), Notes (textarea). Submit calls POST /api/warehouses. 3) **Edit warehouse**: Same form pre-filled, PUT /api/warehouses/{id}. 4) **Deactivate warehouse**: Confirmation dialog (can't deactivate if barrels still stored there). Sets is_active = false. Warehouse hidden from dropdowns but remains in database for historical data. 5) **Warehouse selector**: In main navigation (top bar or sidebar), dropdown to select active warehouse. Filters all barrel/order data to selected warehouse. Store selection in Redux: selectedWarehouseId. If user has access to multiple warehouses, show 'All Warehouses' option to view combined data. 6) **Integration**: Update BarrelsListPage, OrdersListPage, Dashboard to filter by selectedWarehouseId. Add warehouse column to barrel list table. Add warehouse filter to all search/filter panels. Backend: Update all GET endpoints to accept optional warehouseId param. Use React Native Paper DataTable, Modal, Select components."
P2-High,Barcode Scanning,Label Printing,SCAN-001,Research thermal printer integration,Research & Analysis,2,19,None,"- Evaluation of thermal printer options (Zebra, Brother, Dymo)
- Label size standards for barrels (2x3 inch, 4x6 inch)
- Barcode format decision (Code128, QR, both)
- Print from web (browser integration) and mobile
- Cost analysis and recommendations","Research barcode label printing solutions for Caskr. Distilleries need to print barrel tags on-demand. Requirements: 1) **Printer options**: Zebra ZD series (industry standard, expensive $300-600), Brother QL series (affordable $100-200, good quality), Dymo LabelWriter (cheapest $80-150, lower quality). All support thermal printing (no ink/toner needed). 2) **Label sizes**: Standard options: 2"" x 1"" (small barrel tag), 2"" x 3"" (barrel bung tag), 4"" x 6"" (full barrel side label with TTB info). Recommendation: 2x3"" for primary use case. 3) **Barcode formats**: Code128 (linear, compact, high density), QR Code (2D, stores more data, works well with phone cameras), Both: Print QR on top, Code128 below for redundancy. Data to encode: Barrel SKU (minimum), or Full URL: https://app.caskr.com/barrels/{sku} (QR code can deep link to app). 4) **Printing from web browser**: Challenge: Browsers can't directly access USB printers for security. Solutions: WebUSB API (experimental, limited browser support), Print driver (user installs driver that exposes printer as network endpoint), Cloud print service (Caskr backend sends print job to cloud, user's computer polls and prints), Electron app (desktop app with native printer access). Recommendation: Start with browser print dialog (user manually prints PDF label), upgrade to WebUSB or print driver later. 5) **Printing from mobile**: iOS/Android: Use printer manufacturer's SDK (Zebra has ZebraPrinter SDK for React Native), or Bluetooth/WiFi connection. Most modern thermal printers support wireless. 6) **Cost**: Printer: $150-600 one-time, Labels: $20-50 per 1000 labels. **Document findings in docs/BARCODE_PRINTING_RESEARCH.md with recommendation**."
P2-High,Barcode Scanning,Label Printing,SCAN-002,Create label template designer,User Interface,5,19,SCAN-001,"- Label template editor UI
- Drag-and-drop elements: Text, barcode, QR code, image
- Element properties: Font, size, position, content
- Template preview
- Save templates for reuse
- Sample data mode for testing","Create label template designer for custom barrel tags. File: caskr.client/src/pages/LabelTemplatesPage.tsx. This allows users to design custom label layouts. Implementation: 1) **Canvas**: HTML5 Canvas or SVG-based editor (consider using Fabric.js library for easier drag-drop). Canvas sized to label dimensions (e.g., 2"" x 3"" at 203 DPI = 406 x 609 pixels). Grid overlay for alignment. 2) **Element toolbox**: Left sidebar with draggable elements: Text (static text or dynamic fields like {{barrel_sku}}, {{batch_name}}, {{fill_date}}), Barcode (Code128, configure data source), QR Code (configure URL or data), Image (upload company logo), Line/Rectangle (decorative elements). Drag element onto canvas to add. 3) **Element properties panel**: Right sidebar shows properties of selected element. For Text: Font (dropdown of web-safe fonts), Size (points), Color (color picker), Bold/Italic toggles, Data source (dropdown: Static text, Barrel SKU, Batch Name, Fill Date, ABV, etc.). For Barcode/QR: Format (Code128, QR), Data source (same as text), Size. For Image: Upload button, Scale controls. 4) **Canvas interactions**: Click element to select (show selection handles), Drag to reposition, Resize handles at corners, Delete key to remove, Duplicate button, Bring to front/Send to back (z-order). 5) **Template metadata**: Template name input at top, Label size dropdown (2x1, 2x3, 4x6), Print orientation (portrait/landscape). 6) **Preview mode**: Toggle 'Preview with Sample Data' shows what label looks like with actual barrel data. Fetch sample barrel from API, replace {{barrel_sku}} placeholders with real values. 7) **Save template**: POST /api/label-templates with {name, label_size, elements: [{type, properties, position}] as JSON}. Saved templates appear in templates list. 8) **Print**: 'Print Test Label' button generates PDF with current template, opens print dialog. Consider using jsPDF library for PDF generation. Complex feature - 5-8 story points."
P2-High,Barcode Scanning,Label Printing,SCAN-003,Create batch label printing,User Interface,3,20,SCAN-002,"- Select multiple barrels for batch printing
- Choose label template
- Preview all labels before printing
- Generate single PDF with all labels
- Support for different label sizes in one print job","Create batch label printing feature. File: caskr.client/src/pages/BatchPrintLabelsPage.tsx or modal from BarrelsListPage. Implementation: 1) **Barrel selection**: In BarrelsListPage, add checkboxes to each row. Select individual barrels or 'Select All' checkbox. Selected count shown in header (e.g., '15 barrels selected'). 2) **Batch print button**: Appears when barrels selected. Opens batch print modal. 3) **Print modal**: Step 1 - Template selection: Dropdown showing saved label templates. Preview thumbnail of template. Step 2 - Label size confirmation: Dropdown (2x1, 2x3, 4x6) - should match template size. Step 3 - Preview: Scrollable list of all labels to be printed. Each label rendered with that barrel's data. User can deselect individual labels if needed. Total label count shown (e.g., 'Printing 15 labels'). 4) **Generate PDF**: Button 'Generate Print File'. Calls POST /api/labels/batch-print with {barrelIds: [...], templateId: 123, labelSize: '2x3'}. Backend: Fetches all barrels, renders each label using template, combines into single PDF with page breaks at label boundaries. Returns PDF file. 5) **Download & print**: PDF downloads automatically, opens in new tab. User can print via browser print dialog. Include print CSS to remove margins/headers. 6) **Printer-specific formats**: Option to export in ZPL (Zebra Programming Language) for direct printing to Zebra printers without PDF (advanced). 7) **Scheduling**: Option to 'Print all barrels filled today' as daily batch job (future enhancement). Use jsPDF or PDFKit (backend) for PDF generation. Backend endpoint: LabelsController.BatchPrint(). This streamlines barrel tagging workflow significantly."
P2-High,API Integration,Public API Documentation,API-001,Create OpenAPI/Swagger documentation,Documentation,3,20,None,"- Swagger UI available at /api/docs
- All endpoints documented with descriptions
- Request/response schemas included
- Authentication requirements noted
- Example requests and responses
- Try it out functionality working","Create comprehensive API documentation using OpenAPI/Swagger. Caskr already uses ASP.NET Core and likely has Swashbuckle installed. Enhance existing docs: 1) **Install/Update Swashbuckle**: In Caskr.server.csproj, ensure latest version: <PackageReference Include=""Swashbuckle.AspNetCore"" Version=""6.5.0"" />. 2) **Configure Swagger in Program.cs**: builder.Services.AddSwaggerGen(options => { options.SwaggerDoc(""v1"", new OpenApiInfo { Title = ""Caskr API"", Version = ""v1"", Description = ""Distillery management system API"", Contact = new OpenApiContact { Name = ""Caskr Support"", Email = ""support@caskr.com"" } }); options.AddSecurityDefinition(""Bearer"", new OpenApiSecurityScheme { Type = SecuritySchemeType.Http, Scheme = ""bearer"", BearerFormat = ""JWT"" }); options.AddSecurityRequirement(new OpenApiSecurityRequirement { ... }); }). Enable in app: app.UseSwagger(); app.UseSwaggerUI(). 3) **Document controllers**: Add XML documentation comments to all controller actions: /// <summary>Gets all barrels for a company</summary> /// <param name=""companyId"">Company ID</param> /// <returns>List of barrels</returns> /// <response code=""200"">Returns barrel list</response> /// <response code=""401"">Unauthorized</response> [ProducesResponseType(typeof(List<Barrel>), 200)] [ProducesResponseType(401)]. 4) **Enable XML comments**: In .csproj: <GenerateDocumentationFile>true</GenerateDocumentationFile>. In Swagger config: options.IncludeXmlComments(Path.Combine(AppContext.BaseDirectory, ""Caskr.Server.xml"")). 5) **Example schemas**: Use [SwaggerSchema] attributes on models to add examples. 6) **Versioning**: Support /api/v1/ and /api/v2/ URLs (future-proofing). 7) **Public access**: Make /api/docs publicly accessible (no auth required) but show auth requirements for each endpoint. This enables third-party integrations and partner development."
P2-High,API Integration,Webhook System,API-002,Design webhook system architecture,Backend Service,5,21,None,"- Webhook subscriptions table (company, event types, target URL, secret)
- Webhook delivery log table (subscription, event, payload, status, retry count)
- Event types defined (barrel.created, order.completed, etc.)
- Retry mechanism with exponential backoff
- Webhook signature for security","Design webhook system to notify external systems of Caskr events. File: docs/WEBHOOK_SYSTEM_DESIGN.md and database migration. Architecture: 1) **Database schema**: File: Database/initdb.d/12-migration-webhooks.sql. Tables: webhook_subscriptions (id, company_id FK, name VARCHAR(200), target_url VARCHAR(500), event_types JSONB array (e.g., ['barrel.created', 'order.completed']), is_active BOOLEAN, secret_key VARCHAR(100) (for HMAC signature), created_by_user_id FK, created_at, updated_at). webhook_deliveries (id, subscription_id FK, event_type VARCHAR(100), event_id INTEGER (ID of triggering entity), payload JSONB (full event data), delivery_status ENUM('Pending', 'Success', 'Failed', 'Retrying'), http_status_code INTEGER, response_body TEXT, retry_count INTEGER DEFAULT 0, next_retry_at TIMESTAMP, delivered_at, created_at). 2) **Event types**: Define standard events: barrel.created, barrel.updated, barrel.deleted, barrel.moved, batch.created, batch.completed, order.created, order.completed, task.created, task.completed, transfer.created, ttb_report.submitted. Store in enum or config file. 3) **Webhook payload format**: Standardize JSON structure: {event_type, event_id, timestamp, data: {entity_data}, company_id}. Example: {event_type: 'barrel.created', event_id: 1234, timestamp: '2024-11-14T10:30:00Z', data: {id: 1234, sku: 'BAR-001', status: 'Filled', ...}, company_id: 1}. 4) **Security**: Generate secret_key (random 32-byte string) when subscription created. Sign payload with HMAC-SHA256 using secret. Include signature in HTTP header: X-Caskr-Signature: sha256=abcdef123.... Receiving system validates signature to ensure authenticity. 5) **Retry logic**: If delivery fails (HTTP status != 2xx or network error), retry with exponential backoff: Retry 1: after 1 min, Retry 2: after 5 min, Retry 3: after 15 min, Retry 4: after 1 hour, Retry 5: after 6 hours. After 5 failed retries, mark subscription as Failed, send alert email to creator. 6) **Rate limiting**: Max 100 webhooks per subscription per minute to prevent abuse. This design enables real-time integrations with external systems (e.g., trigger Slack notification when order completed, sync data to custom analytics platform)."
P2-High,API Integration,Webhook System,API-003,Implement webhook delivery service,Backend Service,8,21,API-002,"- Service fires webhooks on domain events
- HTTP client sends POST to target URL with payload
- Signature calculation and header injection
- Async delivery (doesn't block main request)
- Retry queue processing
- Logging all deliveries","Implement webhook delivery service. Files: Caskr.Server/Services/WebhookService.cs and background job. Implementation: 1) **Interface and service**: IWebhookService with methods: Task TriggerEventAsync(string eventType, int eventId, object eventData), Task<WebhookSubscription> CreateSubscriptionAsync(int companyId, WebhookSubscriptionRequest request), Task DeactivateSubscriptionAsync(int subscriptionId). Create WebhookService implementing interface. 2) **TriggerEventAsync implementation**: Fetch active subscriptions for this company WHERE event_types CONTAINS eventType (JSONB query). For each subscription: Create webhook_deliveries record with status = Pending. Queue delivery job (don't send immediately to avoid blocking). 3) **Webhook delivery worker**: Background service: WebhookDeliveryWorker : IHostedService. Runs continuously: Query webhook_deliveries WHERE delivery_status IN ('Pending', 'Retrying') AND next_retry_at <= NOW() ORDER BY created_at LIMIT 100. For each delivery: Build payload JSON from event data. Calculate HMAC signature: var signature = HMAC_SHA256(secret_key, payload); var signatureHeader = $""sha256={signature}"". Send HTTP POST to target_url with headers: Content-Type: application/json, X-Caskr-Signature: {signatureHeader}, User-Agent: Caskr-Webhooks/1.0. Timeout: 10 seconds. If success (status 200-299): Update delivery_status = Success, delivered_at = NOW(). If failure: Increment retry_count, Calculate next_retry_at using exponential backoff, Update delivery_status = Retrying or Failed (if retry_count >= 5). 4) **Domain event integration**: In BarrelsService, after barrel created, call webhookService.TriggerEventAsync(""barrel.created"", barrel.Id, barrel). Similar for all other domain events. Use MediatR library for clean event-driven architecture (optional). 5) **HTTP client**: Use HttpClient with retry policies (Polly library for transient failures). 6) **Logging**: Log all webhook deliveries (ILogger), include subscription ID, event type, status, response time. Critical for debugging integration issues. This enables real-time integrations. Test with webhook.site for easy testing."
P2-High,Customer Portals,Cask Ownership Portal,PORTAL-001,Design customer portal data model,Database Schema,3,22,None,"- Customer portal users table (separate from main users)
- Cask ownership records (customer, barrel, purchase info)
- Portal permissions and access levels
- Viewing history and activity logs","Design database schema for customer/investor portals. Allows external customers to view their cask investments. File: Database/initdb.d/13-migration-customer-portal.sql. Tables: 1) portal_users (id, email VARCHAR(200) UNIQUE, password_hash VARCHAR(500), first_name, last_name, phone, company_id FK (which distillery they're a customer of), is_active BOOLEAN, email_verified BOOLEAN, verification_token, password_reset_token, last_login_at, created_at). Separate from main users table for security (customers shouldn't access main app). 2) cask_ownerships (id, portal_user_id FK, barrel_id FK, purchase_date DATE, purchase_price DECIMAL(10,2), ownership_percentage DECIMAL(5,2) (allows fractional ownership), certificate_number VARCHAR(100), status ENUM('Active', 'Matured', 'Bottled', 'Sold'), notes TEXT, created_at). Links customers to their barrels. 3) portal_access_logs (id, portal_user_id FK, action VARCHAR(100) (Login, View_Barrel, Download_Certificate), ip_address VARCHAR(45), user_agent TEXT, accessed_at). Audit trail for security. 4) portal_documents (id, cask_ownership_id FK, document_type ENUM('Ownership_Certificate', 'Insurance_Document', 'Maturation_Report', 'Photo'), file_path VARCHAR(500), uploaded_by_user_id FK (distillery staff who uploaded), uploaded_at). Stores documents accessible to customers. 5) portal_notifications (id, portal_user_id FK, notification_type ENUM('Barrel_Milestone', 'Maturation_Update', 'Ready_For_Bottling'), title VARCHAR(200), message TEXT, is_read BOOLEAN DEFAULT false, sent_at). In-app notifications for portal users. Indexes on (company_id, email), (portal_user_id, barrel_id). This schema supports cask investment programs where customers buy individual barrels and track their aging."
P2-High,Customer Portals,Cask Ownership Portal,PORTAL-002,Create customer portal authentication,Backend Service,5,22,PORTAL-001,"- Separate auth for portal users (different from main app)
- Email/password registration and login
- Email verification required
- Password reset workflow
- JWT tokens for API access
- Security hardened (rate limiting, brute force protection)","Implement authentication for customer portal. Separate from main Keycloak SSO (customers don't need SSO). File: Caskr.Server/Controllers/PortalAuthController.cs and services. Implementation: 1) **Registration**: Endpoint: POST /api/portal/auth/register. Request: {email, password, firstName, lastName, phone, companyId (which distillery)}. Validation: Email format, password strength (min 8 chars, uppercase, lowercase, number), email not already registered. Hash password with BCrypt: var passwordHash = BCrypt.Net.BCrypt.HashPassword(password). Create portal_users record with email_verified = false. Generate verification token: var token = Guid.NewGuid().ToString(). Send verification email: Subject: 'Verify your email', Body: 'Click here to verify: https://portal.caskr.com/verify?token={token}'. Return success message (don't auto-login until verified). 2) **Email verification**: Endpoint: GET /api/portal/auth/verify?token={token}. Find portal_users WHERE verification_token = {token}. Set email_verified = true, clear token. Redirect to login page with success message. 3) **Login**: Endpoint: POST /api/portal/auth/login. Request: {email, password}. Find portal_user WHERE email = {email} AND is_active = true. Verify password: BCrypt.Net.BCrypt.Verify(password, user.password_hash). If invalid, increment failed_login_attempts. If attempts > 5, lock account for 30 min (rate limiting). If valid: Generate JWT token with claims: {userId, email, companyId, role: 'PortalUser'}. Token expiration: 24 hours. Return {accessToken, user: {id, email, firstName, lastName}}. Log login in portal_access_logs. 4) **Password reset**: Endpoint: POST /api/portal/auth/forgot-password. Request: {email}. Generate reset token, send email with link. Endpoint: POST /api/portal/auth/reset-password. Request: {token, newPassword}. Validate token, hash new password, update user. 5) **Logout**: Frontend clears token. Optional: Maintain token blacklist for immediate invalidation. Use ASP.NET Core Identity for password hashing/validation, or manual implementation with BCrypt. Add rate limiting middleware to prevent brute force attacks."
P2-High,Customer Portals,Cask Ownership Portal,PORTAL-003,Create customer portal UI,User Interface,8,23,PORTAL-002,"- Public-facing customer portal (separate from main Caskr app)
- Login/registration screens
- Dashboard showing customer's barrels
- Barrel detail page with aging info, photos, documents
- Download ownership certificates
- Contact distillery form","Create customer-facing portal application. This is a separate React app from the main Caskr client (different audience, different design). File structure: caskr.portal/ (new directory, separate React app). Implementation: 1) **Initialize app**: npx create-react-app caskr-portal --template typescript. Install dependencies: React Router, Redux Toolkit, Axios, React Hook Form, date-fns. 2) **Authentication screens**: /portal/login: Email/password login form, 'Forgot Password?' link, 'Don't have an account? Register' link. /portal/register: Registration form (email, password, confirm password, first name, last name, phone), Terms & Conditions checkbox, Submit calls POST /api/portal/auth/register. /portal/verify-email: Shows 'Please check your email' message after registration. Verify link (from email) redirects here, calls verification endpoint, shows success. /portal/forgot-password: Enter email, sends reset link. /portal/reset-password: Enter new password with token from email link. 3) **Dashboard** (/portal/dashboard): Header with portal user's name, logout button. Welcome message: 'Welcome back, John!'. List of customer's barrels (GET /api/portal/barrels). Each card shows: Barrel SKU (or custom name like 'My Bourbon Barrel'), Purchase date, Age in storage (calculated from fill date), Current location (Warehouse, Rick, Tier), Photo thumbnail (if uploaded by distillery), Status (Aging, Ready for Bottling, Bottled). Click card to navigate to barrel detail. 4) **Barrel detail page** (/portal/barrels/{id}): Full barrel information: Barrel details (SKU, batch, fill date, age, proof, volume), Maturation progress bar (e.g., '3 years of 5 year aging'), Aging chart (proof/volume over time if historical data exists), Photos carousel (distillery can upload photos of barrel), Documents list: Ownership Certificate (PDF download), Insurance document, Maturation reports (quarterly or annual reports from distillery). Action buttons: 'Download All Documents' (ZIP file), 'Contact Distillery' (opens contact form modal). 5) **Branding**: Use distillery's branding (logo, colors) if white-label option. Default: Caskr portal branding. 6) **Responsive**: Mobile-friendly design (customers likely viewing on phone). Use Material-UI or Chakra UI for clean, professional look. Deploy portal separately: portal.caskr.com or {distillery}.caskr.com (white-label subdomain)."
P3-NiceToHave,Quality Control,Lab Management,QC-001,Design lab management data model,Database Schema,5,24,None,"- Lab tests and analyses tracking
- Organoleptic evaluations (tasting notes)
- Chemical analysis results (ABV, pH, congeners)
- Quality checkpoints in production workflow
- Historical trending and comparison","Create database schema for quality control and lab management. File: Database/initdb.d/14-migration-quality-control.sql. Tables: 1) lab_test_types (id, test_name VARCHAR(200), test_category ENUM('Chemical', 'Organoleptic', 'Physical', 'Microbial'), description TEXT, required_equipment TEXT, standard_procedure TEXT, typical_frequency VARCHAR(100)). Examples: 'ABV Measurement', 'pH Test', 'Congener Analysis', 'Color Assessment', 'Sensory Evaluation'. 2) lab_tests (id, batch_id FK (optional), barrel_id FK (optional), test_type_id FK, test_date DATE, tested_by_user_id FK, status ENUM('Scheduled', 'In_Progress', 'Completed', 'Failed'), notes TEXT, created_at). Links tests to batches or barrels. 3) lab_test_results (id, lab_test_id FK, parameter_name VARCHAR(100), measured_value DECIMAL(10,4), unit VARCHAR(50), expected_range_min DECIMAL(10,4), expected_range_max DECIMAL(10,4), is_within_spec BOOLEAN, notes TEXT). Example: {parameter: 'ABV', value: 62.5, unit: '% alcohol by volume', expected_min: 60, expected_max: 65, within_spec: true}. Multiple results per test for multi-parameter tests. 4) sensory_evaluations (id, batch_id FK, barrel_id FK, evaluation_date DATE, evaluator_user_id FK, aroma_notes TEXT, taste_notes TEXT, mouthfeel_notes TEXT, finish_notes TEXT, overall_score INTEGER (1-10), defects TEXT, recommendation ENUM('Approve', 'Continue_Aging', 'Reject', 'Blend'), created_at). Tasting panel assessments. 5) quality_checkpoints (id, checkpoint_type ENUM('Pre_Mash', 'Post_Fermentation', 'Post_Distillation', 'Pre_Barrel', 'Mid_Aging', 'Pre_Bottling'), batch_id FK, checkpoint_date DATE, inspector_user_id FK, status ENUM('Pass', 'Fail', 'Conditional'), issues TEXT, corrective_actions TEXT). Quality gates in production workflow. Indexes on (batch_id, test_date), (barrel_id, test_date). This enables comprehensive quality tracking and regulatory compliance (especially for export markets requiring chemical analysis certificates)."
P3-NiceToHave,Quality Control,Lab Management,QC-002,Create lab test entry UI,User Interface,5,24,QC-001,"- Lab tests page with list of all tests
- Create new test form (select type, batch/barrel, date)
- Enter test results (dynamic form based on test type)
- Flag out-of-spec results automatically
- View historical test results for a batch/barrel","Create UI for lab technicians to record test results. File: caskr.client/src/pages/LabTestsPage.tsx. Implementation: 1) **Tests list**: Table showing all lab tests. Columns: [Test Date | Test Type | Batch/Barrel | Tested By | Status | Actions]. Filters: Date range, Test type, Status. Search by batch ID or barrel SKU. 2) **Create test button**: Opens modal/form. Select test type (dropdown of lab_test_types). Select subject: Batch (autocomplete search) OR Barrel (autocomplete or scan). Test date (date picker, default today). Tested by (dropdown of lab users, default current user). Notes (optional textarea). Submit creates lab_tests record with status = Scheduled or In_Progress. 3) **Enter results screen** (/lab-tests/{id}/results): Shows test details (type, subject, date, tester). Dynamic results form based on test type: For each parameter in test type (fetch from lab_test_types.parameters if configured, or allow custom entry). Row with: Parameter name, Measured value (number input), Unit (text), Expected range (min-max, pre-filled if standard), Within spec (auto-calculated checkbox, green if value between min-max, red if outside). Example: ABV | [62.5] | % | 60 - 65 | ✓ Within Spec. Notes field for each parameter. Overall test notes. Complete button changes status to Completed, saves all results to lab_test_results. 4) **Out-of-spec handling**: If any parameter out of spec (is_within_spec = false), show warning banner: 'Test failed - 2 parameters out of specification'. Require additional notes explaining issue. Optional: Create task for follow-up action (re-test, adjust process, escalate to production manager). 5) **Historical results**: In batch detail and barrel detail pages, add 'Lab Tests' tab. Shows all tests for that batch/barrel. Timeline view with test dates. Click test to view full results. Trending chart (line graph) for key parameters over time (e.g., ABV trend for barrel over aging period). 6) **Certificates**: Button to generate 'Certificate of Analysis' PDF for export customers (shows all test results in formatted report). Use existing PDF generation service. This enables rigorous quality control and documentation for premium spirits production."
P3-NiceToHave,Supply Chain,Supplier Management,SCM-001,Create supplier management data model,Database Schema,3,25,None,"- Suppliers table (name, contact info, supplier type)
- Purchase orders table
- Inventory receiving workflow
- Supplier product catalog
- Pricing history","Create database schema for supply chain management. File: Database/initdb.d/15-migration-supply-chain.sql. Tables: 1) suppliers (id, company_id FK, supplier_name VARCHAR(200), supplier_type ENUM('Grain', 'Cooperage', 'Bottles', 'Labels', 'Chemicals', 'Equipment', 'Other'), contact_person VARCHAR(200), email, phone, address TEXT, website, payment_terms VARCHAR(100) (e.g., 'Net 30', 'COD'), is_active BOOLEAN, notes TEXT, created_at). 2) supplier_products (id, supplier_id FK, product_name VARCHAR(200), product_category VARCHAR(100), sku VARCHAR(100), unit_of_measure VARCHAR(50), current_price DECIMAL(10,2), currency VARCHAR(3) DEFAULT 'USD', lead_time_days INTEGER, minimum_order_quantity INTEGER, notes TEXT). Catalog of products each supplier offers. 3) purchase_orders (id, company_id FK, supplier_id FK, po_number VARCHAR(100) UNIQUE, order_date DATE, expected_delivery_date DATE, status ENUM('Draft', 'Sent', 'Confirmed', 'Partial_Received', 'Received', 'Cancelled'), total_amount DECIMAL(12,2), currency VARCHAR(3), payment_status ENUM('Unpaid', 'Partial', 'Paid'), notes TEXT, created_by_user_id FK, created_at). 4) purchase_order_items (id, purchase_order_id FK, supplier_product_id FK, quantity DECIMAL(10,2), unit_price DECIMAL(10,2), total_price DECIMAL(10,2), received_quantity DECIMAL(10,2) DEFAULT 0, notes TEXT). Line items in PO. 5) inventory_receipts (id, purchase_order_id FK, receipt_date DATE, received_by_user_id FK, notes TEXT, created_at). Records receiving of goods. 6) inventory_receipt_items (id, inventory_receipt_id FK, purchase_order_item_id FK, received_quantity DECIMAL(10,2), condition ENUM('Good', 'Damaged', 'Partial'), notes TEXT). Details of what was received. 7) supplier_price_history (id, supplier_product_id FK, effective_date DATE, price DECIMAL(10,2), changed_by_user_id FK, change_reason TEXT). Track price changes for cost analysis. Indexes on (company_id, supplier_id), (po_number), (order_date). This enables procurement tracking and inventory receiving workflows."
P3-NiceToHave,Supply Chain,Supplier Management,SCM-002,Create purchase order UI,User Interface,5,25,SCM-001,"- PO creation form
- Line item management (add/remove items)
- Send PO to supplier (email PDF)
- Track PO status
- Receiving workflow (partial and full)","Create purchase order management UI. File: caskr.client/src/pages/PurchaseOrdersPage.tsx. Implementation: 1) **PO list**: Table showing all POs. Columns: [PO Number | Supplier | Order Date | Delivery Date | Status | Total | Actions]. Filters: Status, Supplier, Date range. Click PO to view details. 2) **Create PO form** (/purchase-orders/new): Select supplier (dropdown with autocomplete). Auto-generate PO number (format: PO-2024-001, incrementing). Order date (default today), Expected delivery date. Line items table: Columns [Product | Quantity | Unit | Price | Total | Actions]. 'Add Item' button: Select from supplier's product catalog (supplier_products WHERE supplier_id = selected). Enter quantity. Unit price auto-filled from supplier_products.current_price (editable). Total = quantity * unit_price. Remove button for each line item. Grand total auto-calculated at bottom. Notes textarea. Save as Draft button (status = Draft), Send to Supplier button (status = Sent, generates PDF, opens email). 3) **PO detail page** (/purchase-orders/{id}): Header: PO number, supplier, dates, status badge. Line items table (read-only or editable if Draft). Action buttons based on status: If Draft: Edit, Send to Supplier, Delete. If Sent/Confirmed: Mark as Received (opens receiving modal), Cancel PO. If Received: View Receipt. Receiving modal: For each line item, input 'Received Quantity' (default = ordered quantity). Condition dropdown (Good, Damaged, Partial). Notes field. Submit creates inventory_receipt and updates purchase_order status. If all items fully received, PO status = Received. If partial, status = Partial_Received. 4) **PDF generation**: Generate PO PDF with company letterhead, supplier address, line items table, total, terms. Use existing PDF service (iText7). 5) **Email integration**: 'Send to Supplier' button opens email modal with: To: supplier.email, Subject: 'Purchase Order #{po_number}', Body: customizable template, Attachment: PO PDF. Send via backend email service. This enables end-to-end procurement workflow from PO creation through receiving."
P3-NiceToHave,CRM Integration,Salesforce Connector,CRM-001,Design CRM integration architecture,Backend Service,3,26,None,"- Integration patterns documented (sync vs async, bidirectional)
- Data mapping: Caskr customers ↔ Salesforce accounts
- Sync frequency and triggers defined
- Error handling and conflict resolution strategy","Design architecture for Salesforce CRM integration. File: docs/CRM_INTEGRATION_DESIGN.md. Design decisions: 1) **Integration pattern**: Bidirectional sync (Caskr ↔ Salesforce). Alternative: One-way (Salesforce → Caskr for sales teams, Caskr → Salesforce for order fulfillment). Recommendation: Start with one-way Salesforce → Caskr (simpler), add bidirectional later. 2) **Data mapping**: Salesforce Account ↔ Caskr Customer entity (create if not exists). Salesforce Opportunity ↔ Caskr Order (when Opportunity stage = Closed Won, create Caskr order). Salesforce Contact ↔ Caskr portal_users (for cask investors). 3) **Sync method**: REST API (Salesforce provides robust REST API). OAuth 2.0 authentication (similar to QuickBooks integration from FIN tasks). Webhooks: Salesforce can call Caskr webhook when Opportunity closed (real-time). Polling: Caskr queries Salesforce every 15 minutes for new/updated records (fallback if webhooks not available). 4) **Sync frequency**: Real-time for critical events (Opportunity closed), Hourly batch sync for account updates, Daily full reconciliation to catch missed changes. 5) **Conflict resolution**: Last-write-wins with timestamp comparison. If record updated in both systems since last sync, use most recent. Manual conflict resolution UI for critical fields (sales team chooses which version to keep). 6) **Error handling**: Retry failed syncs (3 attempts with exponential backoff). Log all sync operations to crm_sync_logs table (similar to accounting_sync_logs from FIN tasks). Alert administrator if sync fails repeatedly. 7) **Database schema**: crm_integrations table (similar to accounting_integrations). crm_sync_logs table. crm_field_mappings table (customizable field mapping per company). Document architecture with diagrams (sequence diagram for sync flow, entity-relationship diagram for data mapping)."
P3-NiceToHave,Tour Management,Tasting Room POS,TOUR-001,Design tour and tasting room data model,Database Schema,3,26,None,"- Tours and events tracking
- Visitor registration and tickets
- Tasting room products (bottles for sale)
- POS transactions
- Inventory for retail products","Create database schema for tour and tasting room management. File: Database/initdb.d/16-migration-tour-management.sql. Tables: 1) tour_types (id, company_id FK, tour_name VARCHAR(200), description TEXT, duration_minutes INTEGER, max_participants INTEGER, price DECIMAL(8,2), includes TEXT (what's included: tasting, merchandise, etc.), is_active BOOLEAN). Different tour offerings (Basic Tour $20, Premium Tasting $50, Private Event $500). 2) tour_schedules (id, tour_type_id FK, tour_date DATE, tour_time TIME, available_spots INTEGER, booked_spots INTEGER, status ENUM('Available', 'Full', 'Cancelled'), guide_user_id FK, notes TEXT). Scheduled tour instances. 3) tour_bookings (id, tour_schedule_id FK, customer_name VARCHAR(200), customer_email, customer_phone, party_size INTEGER, total_price DECIMAL(8,2), booking_status ENUM('Pending', 'Confirmed', 'Completed', 'Cancelled', 'No_Show'), payment_status ENUM('Unpaid', 'Paid', 'Refunded'), booked_at, confirmed_at, completed_at). Customer reservations. 4) retail_products (id, company_id FK, product_name VARCHAR(200), product_type ENUM('Bottle', 'Merchandise', 'Gift_Set'), sku VARCHAR(100), price DECIMAL(8,2), cost DECIMAL(8,2), inventory_quantity INTEGER, low_stock_threshold INTEGER, image_url VARCHAR(500), description TEXT, is_active BOOLEAN). Products sold in tasting room (bottles, t-shirts, glassware, etc.). 5) pos_transactions (id, company_id FK, transaction_date TIMESTAMP, transaction_type ENUM('Sale', 'Return', 'Void'), customer_name VARCHAR(200), subtotal DECIMAL(10,2), tax DECIMAL(8,2), total DECIMAL(10,2), payment_method ENUM('Cash', 'Credit_Card', 'Gift_Card'), cashier_user_id FK, tour_booking_id FK (if part of tour), notes TEXT). 6) pos_transaction_items (id, pos_transaction_id FK, retail_product_id FK, quantity INTEGER, unit_price DECIMAL(8,2), total_price DECIMAL(10,2)). Line items. 7) tasting_room_sessions (id, company_id FK, session_date DATE, opening_cash DECIMAL(8,2), closing_cash DECIMAL(8,2), total_sales DECIMAL(10,2), variance DECIMAL(8,2), closed_by_user_id FK, closed_at). Daily cash drawer reconciliation. This enables full tasting room and tour operations management."
P3-NiceToHave,Tour Management,Tasting Room POS,TOUR-002,Create simple POS UI,User Interface,8,27,TOUR-001,"- Touch-friendly POS interface for iPad/tablet
- Product grid with images
- Shopping cart with add/remove
- Payment processing (cash, card)
- Receipt generation and printing
- End-of-day cash drawer reconciliation","Create point-of-sale UI for tasting room. File: caskr.client/src/pages/TastingRoomPOSPage.tsx. This is a full-screen touch-optimized interface for iPad or tablet at tasting room counter. Implementation: 1) **Layout**: Left side (60%): Product grid. Right side (40%): Shopping cart and payment. 2) **Product grid**: Display all retail_products in grid (4 columns on tablet). Each product card: Product image (or placeholder), Product name, Price (large, bold). Tap card to add to cart (qty +1). Long-press to open quantity dialog (enter custom qty). Filter tabs at top: All Products, Bottles, Merchandise. Search bar for quick product lookup. 3) **Shopping cart**: Header: 'Current Sale'. List of items in cart: Product name, Quantity (with +/- buttons to adjust), Unit price, Total price (qty * price), Remove button (X). Cart footer: Subtotal, Tax (calculate based on company tax rate - fetch from company settings), Total (large, bold). Clear cart button. 4) **Payment area**: Payment method buttons (large, touch-friendly): Cash, Credit Card, Gift Card. Cash payment flow: Enter amount received (number pad), Show change due (calculated: amount_received - total). Complete sale button. Credit Card flow: 'Swipe/Insert Card' message (integration with payment terminal - Square, Stripe Terminal, or manual entry for MVP). Enter last 4 digits for record. Complete sale button. 5) **Complete sale**: Create pos_transaction and pos_transaction_items records. Decrement retail_products.inventory_quantity for each item. Print receipt (thermal printer or browser print): Receipt header (distillery name, address), Transaction ID and date/time, Itemized list, Subtotal/Tax/Total, Payment method, Thank you message. Open cash drawer (if connected hardware). Show 'Sale Complete' confirmation, auto-clear cart after 2 seconds. 6) **End-of-day reconciliation**: Button 'Close Drawer' (only for managers). Enter opening cash amount (from previous day's closing). System shows: Total cash sales (from pos_transactions), Expected cash in drawer (opening + sales - change given), User enters counted cash amount. Variance = counted - expected. If variance != 0, require notes. Create tasting_room_sessions record. Print reconciliation report. 7) **Touch optimizations**: Large buttons (min 44x44px for touch), Swipe gestures for cart management, On-screen keyboard for product search, Minimal text input (mostly taps). Use bright colors, high contrast for readability in various lighting. Consider using a dedicated POS framework like React POS or build custom. Integrate with Square/Stripe for payment processing (SDKs available for React). This is a significant feature - 8-13 story points for full implementation."
P3-NiceToHave,AI Features,Demand Forecasting,AI-001,Research ML forecasting approaches,Research & Analysis,5,28,None,"- Evaluation of forecasting methods (ARIMA, Prophet, LSTM)
- Data requirements analysis (historical sales, seasonality, events)
- POC implementation with historical data
- Accuracy metrics and validation
- Recommendation for implementation","Research machine learning approaches for demand forecasting. This helps distilleries predict future sales and plan production/aging accordingly. File: docs/ML_FORECASTING_RESEARCH.md. Research areas: 1) **Forecasting methods**: ARIMA (AutoRegressive Integrated Moving Average): Classical time series method, good for linear trends, requires stationary data. Prophet (Facebook's forecasting tool): Handles seasonality and holidays well, easy to use, good for business time series with multiple seasonality (weekly, monthly, annual). LSTM (Long Short-Term Memory neural networks): Deep learning approach, can capture complex patterns, requires more data (3+ years). Recommendation: Start with Prophet (easiest, good results for most business cases). 2) **Data requirements**: Minimum historical data: 2 years of sales data for annual seasonality. Features to include: Historical sales volume by product, Seasonal factors (holidays, summer vs winter), Promotional events (special releases, tours), Economic indicators (optional: GDP, consumer spending), Weather data (tourism affected by weather). Target variable: Monthly or weekly sales volume by product type. 3) **POC implementation**: Use Python with Prophet library. Load historical data from Caskr database (orders table). Split data: Train on first 80%, test on last 20%. Fit Prophet model: model = Prophet(yearly_seasonality=True, weekly_seasonality=False). Add custom seasonality for distillery events. Generate forecast for next 12 months. Evaluate accuracy: Mean Absolute Percentage Error (MAPE) on test set. Target: <20% MAPE for usable forecast. 4) **Challenges**: Limited historical data for new distilleries (Prophet handles this better than ARIMA/LSTM). Product launches (no historical data for new products - use similar product's history). Black swan events (COVID-19 disrupted all forecasts - need override capability). 5) **Integration with Caskr**: Train model monthly with latest data. Store forecasts in database (demand_forecasts table). Display in dashboard: Forecasted sales vs actual, confidence intervals (80%, 95%). Use forecasts to recommend production quantities (Production Planning module from TTB-012). 6) **Tools**: Python backend service (Flask or FastAPI), Prophet library, Pandas for data manipulation. Host on separate server or serverless function (AWS Lambda, Azure Functions). Caskr API calls forecasting service when needed. Document findings with sample forecast charts, accuracy metrics, recommended approach. This is P3 (nice-to-have) as it requires significant ML expertise and data. Deliver business value only after several years of historical data accumulated."
